{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6A7Q1EKppw8L"
      },
      "source": [
        "In this code, we are building a deep learning model using the Xception architecture as a feature extractor, followed by an SVM (Support Vector Machine) for classification. Initially, we load the pre-trained Xception model (without the top classification layer) and apply global average pooling on the output to reduce its dimensionality. Then, we create a new output layer with 2048 units and a ReLU activation function, which serves as an intermediate feature representation.\n",
        "\n",
        "We then train the model to extract these features from images, specifically categorizing images as either 'Necrosis' or 'Non_Necrosis.' The features from the Xception model are saved as CSV files, along with the image labels and filenames. These features are then used to train an SVM classifier, which is evaluated based on performance metrics such as precision, recall, F1 score, accuracy, sensitivity, specificity, and AUC-ROC.\n",
        "\n",
        "For multiple batches, the code processes training and testing image data, extracts features using Xception, trains the SVM model, and stores the evaluation results in CSV files. The overall goal is to combine deep learning feature extraction with a traditional machine learning classifier (SVM) to detect and classify images based on the presence of necrosis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "4zAqxp6xurFk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IKUkkiopvUu_"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking for zip file at: /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/necrosisData/WR_Necrosis 3.0.zip\n",
            "Will extract to: /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/WR_Necrosis 3.0\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Get the current notebook's directory and navigate to the correct location\n",
        "current_dir = os.path.dirname(os.path.abspath('__file__'))\n",
        "# Go up to first pathologyStudentsAug25\n",
        "parent_dir = os.path.dirname(current_dir)\n",
        "# Go up to Downloads\n",
        "root_dir = os.path.dirname(parent_dir)\n",
        "# Construct path to zip file\n",
        "path_to_zip_file = os.path.join(root_dir, 'pathologyStudentsAug25', 'necrosisData', 'WR_Necrosis 3.0.zip')\n",
        "\n",
        "# Create extraction directory\n",
        "extract_dir = os.path.join(root_dir, 'pathologyStudentsAug25', 'WR_Necrosis 3.0')\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Looking for zip file at: {path_to_zip_file}\")\n",
        "print(f\"Will extract to: {extract_dir}\")\n",
        "\n",
        "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "LmhNkymAvUx7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking for zip file at: /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/necrosisData/WR_Non Necrosis 3.0.zip\n",
            "Will extract to: /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/WR_Non_Necrosis 3.0\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Get the current notebook's directory and navigate to the correct location\n",
        "current_dir = os.path.dirname(os.path.abspath('__file__'))\n",
        "# Go up to first pathologyStudentsAug25\n",
        "parent_dir = os.path.dirname(current_dir)\n",
        "# Go up to Downloads\n",
        "root_dir = os.path.dirname(parent_dir)\n",
        "# Construct path to zip file\n",
        "path_to_zip_file = os.path.join(root_dir, 'pathologyStudentsAug25', 'necrosisData', 'WR_Non Necrosis 3.0.zip')\n",
        "\n",
        "# Create extraction directory\n",
        "extract_dir = os.path.join(root_dir, 'pathologyStudentsAug25', 'WR_Non_Necrosis 3.0')\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Looking for zip file at: {path_to_zip_file}\")\n",
        "print(f\"Will extract to: {extract_dir}\")\n",
        "\n",
        "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "yi9vZLPLvU0W"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "import shutil\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Eui56bGcvYGX"
      },
      "outputs": [],
      "source": [
        "def batch_preparation(batch_number,N_train,NN_train,N_test,NN_test,N_train_per,NN_train_per,N_test_per,NN_test_per):\n",
        "  # Get the current notebook's directory and navigate to the correct location\n",
        "  current_dir = os.path.dirname(os.path.abspath('__file__'))\n",
        "  parent_dir = os.path.dirname(current_dir)\n",
        "  root_dir = os.path.dirname(parent_dir)\n",
        "  \n",
        "  # Create batch directory structure\n",
        "  batch_dir = os.path.join(root_dir, 'pathologyStudentsAug25','original', f'Batch_{batch_number}')\n",
        "  os.makedirs(os.path.join(batch_dir, 'Training', 'Necrosis'), exist_ok=True)\n",
        "  os.makedirs(os.path.join(batch_dir, 'Training', 'Non_Necrosis'), exist_ok=True)\n",
        "  os.makedirs(os.path.join(batch_dir, 'Testing', 'Necrosis'), exist_ok=True)\n",
        "  os.makedirs(os.path.join(batch_dir, 'Testing', 'Non_Necrosis'), exist_ok=True)\n",
        "\n",
        "  # Define source directories\n",
        "  necrosis_dir = os.path.join(root_dir, 'pathologyStudentsAug25', 'WR_Necrosis 3.0')\n",
        "  non_necrosis_dir = os.path.join(root_dir, 'pathologyStudentsAug25', 'WR_Non_Necrosis 3.0')\n",
        "  runtime_dir = os.path.join(root_dir, 'pathologyStudentsAug25', 'Run_time_Folder')\n",
        "\n",
        "  for i in range(len(N_train)):\n",
        "    N_train[i]=str(N_train[i])\n",
        "    if N_train_per[i]==1:\n",
        "      print('Processing Necrosis in Training for Sample Number {} '.format(N_train[i]))\n",
        "      print('\\n')\n",
        "      src_dir = os.path.join(necrosis_dir, 'Sample ' + N_train[i])\n",
        "      dst_dir = os.path.join(batch_dir, 'Training', 'Necrosis')\n",
        "      for jpgfile in glob.iglob(os.path.join(src_dir, \"*.png\")):\n",
        "        shutil.copy(jpgfile, dst_dir)\n",
        "    else:\n",
        "      print('Processing Necrosis in Testing for Sample Number {}'.format(N_train[i]))\n",
        "      print('\\n')\n",
        "      src_dir = os.path.join(necrosis_dir, 'Sample ' + N_train[i])\n",
        "      files_names = os.listdir(src_dir)\n",
        "      files_count = len(files_names)\n",
        "      selected_number_of_files = int(N_train_per[i]*files_count)\n",
        "      selected_files = files_names[0:selected_number_of_files]\n",
        "      os.makedirs(runtime_dir, exist_ok=True)\n",
        "      for j in range(selected_number_of_files):\n",
        "        shutil.copy(os.path.join(src_dir, selected_files[j]), runtime_dir)\n",
        "      dst_dir = os.path.join(batch_dir, 'Training', 'Necrosis')\n",
        "      for jpgfile in glob.iglob(os.path.join(runtime_dir, \"*.png\")):\n",
        "        shutil.copy(jpgfile, dst_dir)\n",
        "      shutil.rmtree(runtime_dir, ignore_errors=True)\n",
        "\n",
        "  for i in range(len(NN_train)):\n",
        "    NN_train[i]=str(NN_train[i])\n",
        "    if NN_train_per[i]==1:\n",
        "      print('Processing Non_Necrosis in Training for Sample Number {}'.format(NN_train[i]))\n",
        "      print('\\n')\n",
        "      src_dir = os.path.join(non_necrosis_dir, 'Sample ' + NN_train[i])\n",
        "      dst_dir = os.path.join(batch_dir, 'Training', 'Non_Necrosis')\n",
        "      for jpgfile in glob.iglob(os.path.join(src_dir, \"*.png\")):\n",
        "        shutil.copy(jpgfile, dst_dir)\n",
        "    else:\n",
        "      print('Processing Non_Necrosis in Testing for Sample Number {}'.format(NN_train[i]))\n",
        "      print('\\n')\n",
        "      src_dir = os.path.join(non_necrosis_dir, 'Sample ' + NN_train[i])\n",
        "      files_names = os.listdir(src_dir)\n",
        "      files_count = len(files_names)\n",
        "      selected_number_of_files = int(NN_train_per[i]*files_count)\n",
        "      selected_files = files_names[0:selected_number_of_files]\n",
        "      os.makedirs(runtime_dir, exist_ok=True)\n",
        "      for j in range(selected_number_of_files):\n",
        "        shutil.copy(os.path.join(src_dir, selected_files[j]), runtime_dir)\n",
        "      dst_dir = os.path.join(batch_dir, 'Training', 'Non_Necrosis')\n",
        "      for jpgfile in glob.iglob(os.path.join(runtime_dir, \"*.png\")):\n",
        "        shutil.copy(jpgfile, dst_dir)\n",
        "      shutil.rmtree(runtime_dir, ignore_errors=True)\n",
        "\n",
        "  for i in range(len(N_test)):\n",
        "    N_test[i]=str(N_test[i])\n",
        "    if N_test_per[i]==1:\n",
        "      print('Processing Necrosis in Testing for Sample Number {}'.format(N_test[i]))\n",
        "      print('\\n')\n",
        "      src_dir = os.path.join(necrosis_dir, 'Sample ' + N_test[i])\n",
        "      dst_dir = os.path.join(batch_dir, 'Testing', 'Necrosis')\n",
        "      for jpgfile in glob.iglob(os.path.join(src_dir, \"*.png\")):\n",
        "        shutil.copy(jpgfile, dst_dir)\n",
        "    else:\n",
        "      print('Processing Necrosis in Testing for Sample Number {}'.format(N_test[i]))\n",
        "      print('\\n')\n",
        "      src_dir = os.path.join(necrosis_dir, 'Sample ' + N_test[i])\n",
        "      files_names = os.listdir(src_dir)\n",
        "      files_count = len(files_names)\n",
        "      selected_number_of_files = int(N_test_per[i]*files_count)\n",
        "      selected_files = files_names[selected_number_of_files:files_count]\n",
        "      os.makedirs(runtime_dir, exist_ok=True)\n",
        "      for j in range(selected_number_of_files):\n",
        "        shutil.copy(os.path.join(src_dir, selected_files[j]), runtime_dir)\n",
        "      dst_dir = os.path.join(batch_dir, 'Testing', 'Necrosis')\n",
        "      for jpgfile in glob.iglob(os.path.join(runtime_dir, \"*.png\")):\n",
        "        shutil.copy(jpgfile, dst_dir)\n",
        "      shutil.rmtree(runtime_dir, ignore_errors=True)\n",
        "\n",
        "  for i in range(len(NN_test)):\n",
        "    NN_test[i]=str(NN_test[i])\n",
        "    if NN_test_per[i]==1:\n",
        "      print('Processing Non Necrosis in Testing for Sample Number {}'.format(NN_test[i]))\n",
        "      print('\\n')\n",
        "      src_dir = os.path.join(non_necrosis_dir, 'Sample ' + NN_test[i])\n",
        "      dst_dir = os.path.join(batch_dir, 'Testing', 'Non_Necrosis')\n",
        "      for jpgfile in glob.iglob(os.path.join(src_dir, \"*.png\")):\n",
        "        shutil.copy(jpgfile, dst_dir)\n",
        "    else:\n",
        "      print('Processing Non Necrosis in Testing for Sample Number {}'.format(NN_test[i]))\n",
        "      src_dir = os.path.join(non_necrosis_dir, 'Sample ' + NN_test[i])\n",
        "      files_names = os.listdir(src_dir)\n",
        "      files_count = len(files_names)\n",
        "      selected_number_of_files = int(NN_test_per[i]*files_count)\n",
        "      selected_files = files_names[selected_number_of_files:files_count]\n",
        "      os.makedirs(runtime_dir, exist_ok=True)\n",
        "      for j in range(selected_number_of_files):\n",
        "        shutil.copy(os.path.join(src_dir, selected_files[j]), runtime_dir)\n",
        "      dst_dir = os.path.join(batch_dir, 'Testing', 'Non_Necrosis')\n",
        "      for jpgfile in glob.iglob(os.path.join(runtime_dir, \"*.png\")):\n",
        "        shutil.copy(jpgfile, dst_dir)\n",
        "      shutil.rmtree(runtime_dir, ignore_errors=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ZeG6CjRTvacq"
      },
      "outputs": [],
      "source": [
        "Batches=[1,2,3,4,5,6,7]\n",
        "\n",
        "\n",
        "B1_Train_N=[7,6,4]\n",
        "B1_Train_Per=[0.8,0.8,0.8]\n",
        "B1_Train_NN=[2,4,5,6,8,9]\n",
        "B1_Train_NN_Per=[0.8,0.8,0.8,0.8,0.8,0.8]\n",
        "B1_Test_N=[2]\n",
        "B1_Test_Per=[0.2]\n",
        "B1_Test_NN=[1]\n",
        "B1_Test_NN_Per=[0.2]\n",
        "\n",
        "B2_Train_N=[7,6,2]\n",
        "B2_Train_Per=[0.8,0.8,0.8]\n",
        "B2_Train_NN=[2,1,4,6,8,9]\n",
        "B2_Train_NN_Per=[0.8,0.8,0.8,0.8,0.8,0.8]\n",
        "B2_Test_N=[4]\n",
        "B2_Test_Per=[0.2]\n",
        "B2_Test_NN=[5]\n",
        "B2_Test_NN_Per=[0.2]\n",
        "\n",
        "B3_Train_N=[7,4,2]\n",
        "B3_Train_Per=[0.8,0.8,0.8]\n",
        "B3_Train_NN=[2,4,5,9,8,1]\n",
        "B3_Train_NN_Per=[0.8,0.8,0.8,0.8,0.8,0.8]\n",
        "B3_Test_N=[6]\n",
        "B3_Test_Per=[0.2]\n",
        "B3_Test_NN=[6]\n",
        "B3_Test_NN_Per=[0.2]\n",
        "\n",
        "B4_Train_N=[7,6,4,2]\n",
        "B4_Train_Per=[0.8,0.8,0.8,0.8]\n",
        "B4_Train_NN=[2,4,5,6,1,9]\n",
        "B4_Train_NN_Per=[0.8,0.8,0.8,0.8,0.8,0.8]\n",
        "B4_Test_N=[7]\n",
        "B4_Test_Per=[0.2]\n",
        "B4_Test_NN=[8]\n",
        "B4_Test_NN_Per=[0.2]\n",
        "\n",
        "B5_Train_N=[7,6,4,2]\n",
        "B5_Train_Per=[0.8,0.8,0.8,0.8]\n",
        "B5_Train_NN=[2,4,5,6,8,9,1]\n",
        "B5_Train_NN_Per=[0.8,0.8,0.8,0.8,0.8,0.8,0.8]\n",
        "B5_Test_N=[7]\n",
        "B5_Test_Per=[0.2]\n",
        "B5_Test_NN=[2]\n",
        "B5_Test_NN_Per=[0.2]\n",
        "\n",
        "\n",
        "B6_Train_N=[7,6,4]\n",
        "B6_Train_Per=[0.8,0.8,0.8]\n",
        "B6_Train_NN=[2,4,5,6,9,1,8]\n",
        "B6_Train_NN_Per=[0.8,0.8,0.8,0.8,0.8,0.8,0.8]\n",
        "B6_Test_N=[2]\n",
        "B6_Test_Per=[0.2]\n",
        "B6_Test_NN=[4]\n",
        "B6_Test_NN_Per=[0.2]\n",
        "\n",
        "B7_Train_N=[7,6,4]\n",
        "B7_Train_Per=[0.8,0.8,0.8]\n",
        "B7_Train_NN=[2,4,5,9,1,8]\n",
        "B7_Train_NN_Per=[0.8,0.8,0.8,0.8,0.8,0.8]\n",
        "B7_Test_N=[2]\n",
        "B7_Test_Per=[0.2]\n",
        "B7_Test_NN=[6]\n",
        "B7_Test_NN_Per=[0.2]\n",
        "\n",
        "Batches=[8,9,10,11,12,13,14,15]\n",
        "\n",
        "B8_Train_N=[2,4,7]\n",
        "B8_Train_Per=[0.8,0.8,0.8]\n",
        "B8_Train_NN=[1,2,4,5,8,9]\n",
        "B8_Train_NN_Per=[0.8,0.8,0.8,0.8,0.8,0.8]\n",
        "B8_Test_N=[6]\n",
        "B8_Test_Per=[0.2]\n",
        "B8_Test_NN=[6]\n",
        "B8_Test_NN_Per=[0.2]\n",
        "\n",
        "\n",
        "\n",
        "B9_Train_N=[6,4,7]\n",
        "B9_Train_Per=[0.8,0.8,0.8]\n",
        "B9_Train_NN=[1,4,5,8,9,6]\n",
        "B9_Train_NN_Per=[0.8,0.8,0.8,0.8,0.8,0.8]\n",
        "B9_Test_N=[2]\n",
        "B9_Test_Per=[0.2]\n",
        "B9_Test_NN=[2]\n",
        "B9_Test_NN_Per=[0.2]\n",
        "\n",
        "\n",
        "B10_Train_N=[6,2,7]\n",
        "B10_Train_Per=[0.8,0.8,0.8]\n",
        "B10_Train_NN=[1,2,5,8,9,6]\n",
        "B10_Train_NN_Per=[0.8,0.8,0.8,0.8,0.8,0.8]\n",
        "B10_Test_N=[4]\n",
        "B10_Test_Per=[0.2]\n",
        "B10_Test_NN=[4]\n",
        "B10_Test_NN_Per=[0.2]\n",
        "\n",
        "B11_Train_N=[6,2,4]\n",
        "B11_Train_Per=[0.8,0.8,0.8]\n",
        "B11_Train_NN=[4,2,5,8,9,6]\n",
        "B11_Train_NN_Per=[0.8,0.8,0.8,0.8,0.8,0.8]\n",
        "B11_Test_N=[7]\n",
        "B11_Test_Per=[0.2]\n",
        "B11_Test_NN=[1]\n",
        "B11_Test_NN_Per=[0.2]\n",
        "\n",
        "\n",
        "B12_Train_N=[6,2,7]\n",
        "B12_Train_Per=[0.8,0.8,0.8]\n",
        "B12_Train_NN=[1,2,5,9,6]\n",
        "B12_Train_NN_Per=[0.8,0.8,0.8,0.8,0.8]\n",
        "B12_Test_N=[4]\n",
        "B12_Test_Per=[0.2]\n",
        "B12_Test_NN=[8]\n",
        "B12_Test_NN_Per=[0.2]\n",
        "\n",
        "\n",
        "B13_Train_N=[6,2,7]\n",
        "B13_Train_Per=[0.8,0.8,0.8]\n",
        "B13_Train_NN=[1,2,5,8,6]\n",
        "B13_Train_NN_Per=[0.8,0.8,0.8,0.8,0.8]\n",
        "B13_Test_N=[4]\n",
        "B13_Test_Per=[0.2]\n",
        "B13_Test_NN=[9]\n",
        "B13_Test_NN_Per=[0.2]\n",
        "\n",
        "\n",
        "B14_Train_N=[6,2,7]\n",
        "B14_Train_Per=[0.8,0.8,0.8]\n",
        "B14_Train_NN=[9,2,5,8,6]\n",
        "B14_Train_NN_Per=[0.8,0.8,0.8,0.8,0.8,0.8]\n",
        "B14_Test_N=[4]\n",
        "B14_Test_Per=[0.2]\n",
        "B14_Test_NN=[1]\n",
        "B14_Test_NN_Per=[0.2]\n",
        "\n",
        "\n",
        "B15_Train_N=[6,2,7]\n",
        "B15_Train_Per=[0.8,0.8,0.8]\n",
        "B15_Train_NN=[1,9,2,8,6]\n",
        "B15_Train_NN_Per=[0.8,0.8,0.8,0.8,0.8]\n",
        "B15_Test_N=[4]\n",
        "B15_Test_Per=[0.2]\n",
        "B15_Test_NN=[5]\n",
        "B15_Test_NN_Per=[0.2]\n",
        "\n",
        "B16_Train_N=[7,6,4]\n",
        "B16_Train_Per=[1,1,1]\n",
        "B16_Train_NN=[1,4,5,6,8,9]\n",
        "B16_Train_NN_Per=[1,1,1,1,1,1]\n",
        "B16_Test_N=[2]\n",
        "B16_Test_Per=[1]\n",
        "B16_Test_NN=[2]\n",
        "B16_Test_NN_Per=[1]\n",
        "\n",
        "B17_Train_N=[7,6,2]\n",
        "B17_Train_Per=[1,1,1]\n",
        "B17_Train_NN=[1,2,5,6,8,9]\n",
        "B17_Train_NN_Per=[1,1,1,1,1,1]\n",
        "B17_Test_N=[4]\n",
        "B17_Test_Per=[1]\n",
        "B17_Test_NN=[4]\n",
        "B17_Test_NN_Per=[1]\n",
        "\n",
        "B18_Train_N=[2,4,7]\n",
        "B18_Train_Per=[1,1,1]\n",
        "B18_Train_NN=[1,2,4,5,8,9]\n",
        "B18_Train_NN_Per=[1,1,1,1,1,1]\n",
        "B18_Test_N=[6]\n",
        "B18_Test_Per=[1]\n",
        "B18_Test_NN=[6]\n",
        "B18_Test_NN_Per=[1]\n",
        "\n",
        "B19_Train_N=[2,4,6]\n",
        "B19_Train_Per=[1,1,1]\n",
        "B19_Train_NN=[1,2,4,5,8,9]\n",
        "B19_Train_NN_Per=[1,1,1,1,1,1]\n",
        "B19_Test_N=[7]\n",
        "B19_Test_Per=[0.2]\n",
        "B19_Test_NN=[7]\n",
        "B19_Test_NN_Per=[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kbUTmLSvi2X",
        "outputId": "df5230c6-ea8b-4d7c-83e9-ed6c71ae5d2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Necrosis in Testing for Sample Number 7\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 5\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 8\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 9\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Non Necrosis in Testing for Sample Number 1\n",
            "Processing Necrosis in Testing for Sample Number 7\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 1\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 8\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 9\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Non Necrosis in Testing for Sample Number 5\n",
            "Processing Necrosis in Testing for Sample Number 7\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 5\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 9\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 8\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 1\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Non Necrosis in Testing for Sample Number 6\n",
            "Processing Necrosis in Testing for Sample Number 7\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 5\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 1\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 9\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 7\n",
            "\n",
            "\n",
            "Processing Non Necrosis in Testing for Sample Number 8\n",
            "Processing Necrosis in Testing for Sample Number 7\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 5\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 8\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 9\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 1\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 7\n",
            "\n",
            "\n",
            "Processing Non Necrosis in Testing for Sample Number 2\n",
            "Processing Necrosis in Testing for Sample Number 7\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 5\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 9\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 1\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 8\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Non Necrosis in Testing for Sample Number 4\n",
            "Processing Necrosis in Testing for Sample Number 7\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 5\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 9\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 1\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 8\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Non Necrosis in Testing for Sample Number 6\n",
            "Processing Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 7\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 1\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 5\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 8\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 9\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Non Necrosis in Testing for Sample Number 6\n",
            "Processing Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 7\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 1\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 5\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 8\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 9\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Non Necrosis in Testing for Sample Number 2\n",
            "Processing Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 7\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 1\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 5\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 8\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 9\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Non Necrosis in Testing for Sample Number 4\n",
            "Processing Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 5\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 8\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 9\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 7\n",
            "\n",
            "\n",
            "Processing Non Necrosis in Testing for Sample Number 1\n",
            "Processing Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 7\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 1\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 5\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 9\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Non Necrosis in Testing for Sample Number 8\n",
            "Processing Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 7\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 1\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 5\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 8\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Non Necrosis in Testing for Sample Number 9\n",
            "Processing Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 7\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 9\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 5\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 8\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Non Necrosis in Testing for Sample Number 1\n",
            "Processing Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 7\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 1\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 9\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 8\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Non Necrosis in Testing for Sample Number 5\n",
            "Processing Necrosis in Training for Sample Number 7 \n",
            "\n",
            "\n",
            "Processing Necrosis in Training for Sample Number 6 \n",
            "\n",
            "\n",
            "Processing Necrosis in Training for Sample Number 4 \n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Training for Sample Number 1\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Training for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Training for Sample Number 5\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Training for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Training for Sample Number 8\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Training for Sample Number 9\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Non Necrosis in Testing for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Necrosis in Training for Sample Number 7 \n",
            "\n",
            "\n",
            "Processing Necrosis in Training for Sample Number 6 \n",
            "\n",
            "\n",
            "Processing Necrosis in Training for Sample Number 2 \n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Training for Sample Number 1\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Training for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Training for Sample Number 5\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Training for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Training for Sample Number 8\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Training for Sample Number 9\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Non Necrosis in Testing for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Necrosis in Training for Sample Number 2 \n",
            "\n",
            "\n",
            "Processing Necrosis in Training for Sample Number 4 \n",
            "\n",
            "\n",
            "Processing Necrosis in Training for Sample Number 7 \n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Training for Sample Number 1\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Training for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Training for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Training for Sample Number 5\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Training for Sample Number 8\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Training for Sample Number 9\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Non Necrosis in Testing for Sample Number 6\n",
            "\n",
            "\n",
            "Processing Necrosis in Training for Sample Number 2 \n",
            "\n",
            "\n",
            "Processing Necrosis in Training for Sample Number 4 \n",
            "\n",
            "\n",
            "Processing Necrosis in Training for Sample Number 6 \n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Training for Sample Number 1\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Training for Sample Number 2\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Training for Sample Number 4\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Training for Sample Number 5\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Training for Sample Number 8\n",
            "\n",
            "\n",
            "Processing Non_Necrosis in Training for Sample Number 9\n",
            "\n",
            "\n",
            "Processing Necrosis in Testing for Sample Number 7\n",
            "\n",
            "\n",
            "Processing Non Necrosis in Testing for Sample Number 7\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "batch_preparation(1,B1_Train_N,B1_Train_NN,B1_Test_N,B1_Test_NN,B1_Train_Per,B1_Train_NN_Per,B1_Test_Per,B1_Test_NN_Per)\n",
        "batch_preparation(2,B2_Train_N,B2_Train_NN,B2_Test_N,B2_Test_NN,B2_Train_Per,B2_Train_NN_Per,B2_Test_Per,B2_Test_NN_Per)\n",
        "batch_preparation(3,B3_Train_N,B3_Train_NN,B3_Test_N,B3_Test_NN,B3_Train_Per,B3_Train_NN_Per,B3_Test_Per,B3_Test_NN_Per)\n",
        "batch_preparation(4,B4_Train_N,B4_Train_NN,B4_Test_N,B4_Test_NN,B4_Train_Per,B4_Train_NN_Per,B4_Test_Per,B4_Test_NN_Per)\n",
        "batch_preparation(5,B5_Train_N,B5_Train_NN,B5_Test_N,B5_Test_NN,B5_Train_Per,B5_Train_NN_Per,B5_Test_Per,B5_Test_NN_Per)\n",
        "batch_preparation(6,B6_Train_N,B6_Train_NN,B6_Test_N,B6_Test_NN,B6_Train_Per,B6_Train_NN_Per,B6_Test_Per,B6_Test_NN_Per)\n",
        "batch_preparation(7,B7_Train_N,B7_Train_NN,B7_Test_N,B7_Test_NN,B7_Train_Per,B7_Train_NN_Per,B7_Test_Per,B7_Test_NN_Per)\n",
        "batch_preparation(8,B8_Train_N,B8_Train_NN,B8_Test_N,B8_Test_NN,B8_Train_Per,B8_Train_NN_Per,B8_Test_Per,B8_Test_NN_Per)\n",
        "batch_preparation(9,B9_Train_N,B9_Train_NN,B9_Test_N,B9_Test_NN,B9_Train_Per,B9_Train_NN_Per,B9_Test_Per,B9_Test_NN_Per)\n",
        "batch_preparation(10,B10_Train_N,B10_Train_NN,B10_Test_N,B10_Test_NN,B10_Train_Per,B10_Train_NN_Per,B10_Test_Per,B10_Test_NN_Per)\n",
        "batch_preparation(11,B11_Train_N,B11_Train_NN,B11_Test_N,B11_Test_NN,B11_Train_Per,B11_Train_NN_Per,B11_Test_Per,B11_Test_NN_Per)\n",
        "batch_preparation(12,B12_Train_N,B12_Train_NN,B12_Test_N,B12_Test_NN,B12_Train_Per,B12_Train_NN_Per,B12_Test_Per,B12_Test_NN_Per)\n",
        "batch_preparation(13,B13_Train_N,B13_Train_NN,B13_Test_N,B13_Test_NN,B13_Train_Per,B13_Train_NN_Per,B13_Test_Per,B13_Test_NN_Per)\n",
        "batch_preparation(14,B14_Train_N,B14_Train_NN,B14_Test_N,B14_Test_NN,B14_Train_Per,B14_Train_NN_Per,B14_Test_Per,B14_Test_NN_Per)\n",
        "batch_preparation(15,B15_Train_N,B15_Train_NN,B15_Test_N,B15_Test_NN,B15_Train_Per,B15_Train_NN_Per,B15_Test_Per,B15_Test_NN_Per)\n",
        "batch_preparation(16,B16_Train_N,B16_Train_NN,B16_Test_N,B16_Test_NN,B16_Train_Per,B16_Train_NN_Per,B16_Test_Per,B16_Test_NN_Per)\n",
        "batch_preparation(17,B17_Train_N,B17_Train_NN,B17_Test_N,B17_Test_NN,B17_Train_Per,B17_Train_NN_Per,B17_Test_Per,B17_Test_NN_Per)\n",
        "batch_preparation(18,B18_Train_N,B18_Train_NN,B18_Test_N,B18_Test_NN,B18_Train_Per,B18_Train_NN_Per,B18_Test_Per,B18_Test_NN_Per)\n",
        "batch_preparation(19,B19_Train_N,B19_Train_NN,B19_Test_N,B19_Test_NN,B19_Train_Per,B19_Train_NN_Per,B19_Test_Per,B19_Test_NN_Per)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VI-q8tnWvlSW",
        "outputId": "68875add-df66-4a83-c818-da5d35f9b29f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 22:40:51.510129: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-12-02 22:40:51.560411: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-12-02 22:40:53.214147: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU memory growth enabled.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1764695454.077116 4187467 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1013 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:04:00.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "# Import basic libraries\n",
        "import os\n",
        "import glob\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Data manipulation and visualization\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Image processing\n",
        "import cv2\n",
        "from skimage.io import imread, imsave\n",
        "from skimage.transform import resize\n",
        "from skimage.feature import hog\n",
        "import skimage.feature as feature\n",
        "\n",
        "# Machine learning\n",
        "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, recall_score, f1_score, precision_score,\n",
        "    cohen_kappa_score, matthews_corrcoef, roc_auc_score,\n",
        "    confusion_matrix\n",
        ")\n",
        "\n",
        "# Deep learning\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.applications import (\n",
        "    DenseNet169, Xception, MobileNet, ResNet50, DenseNet121,\n",
        "    EfficientNetB0, VGG16, MobileNetV2, ResNet101,\n",
        "    InceptionResNetV2, InceptionV3, NASNetMobile\n",
        ")\n",
        "from tensorflow.keras.layers import (\n",
        "    Conv2D, MaxPooling2D, Dense, Flatten,\n",
        "    Dropout, BatchNormalization, GlobalAveragePooling2D\n",
        ")\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
        "from tensorflow.keras.callbacks import (\n",
        "    EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        ")\n",
        "\n",
        "# Enable eager execution for TensorFlow\n",
        "tf.config.run_functions_eagerly(True)\n",
        "# =========================================\n",
        "# FIX 2: Enable dynamic GPU memory allocation\n",
        "# =========================================\n",
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# Enable dynamic memory growth\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:        # <-- FIXED HERE\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        print(\"GPU memory growth enabled.\")\n",
        "    except Exception as e:\n",
        "        print(\"Memory growth error:\", e)\n",
        "else:\n",
        "    print(\"No GPU detected.\")\n",
        "\n",
        "# Create the Xception model with feature extraction\n",
        "base_model_Xception = Xception(\n",
        "    input_shape=(256, 256, 3),\n",
        "    weights='imagenet',\n",
        "    include_top=False\n",
        ")\n",
        "\n",
        "# Add global average pooling\n",
        "output_1 = GlobalAveragePooling2D()(base_model_Xception.output)\n",
        "\n",
        "# Add dense layer for feature extraction\n",
        "output_4 = Dense(2048, activation='relu')(output_1)\n",
        "model_Xception_features_2048 = Model(base_model_Xception.input, output_4)\n",
        "\n",
        "# Add final classification layer\n",
        "output = Dense(2, activation='softmax')(output_1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            " STARTING OPTIMIZED FEATURE EXTRACTION (ReLU + TRAINED)\n",
            "============================================================\n",
            "\n",
            "Found 4586 images belonging to 2 classes.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3514 images belonging to 2 classes.\n",
            "Found 4586 images belonging to 2 classes.\n",
            "Found 3514 images belonging to 2 classes.\n",
            "[INFO] Building model for first time\n",
            "[INFO] Model created  Base frozen + Trainable Dense(2048, ReLU)\n",
            "\n",
            "[TRAINING]  Training Dense(2048, ReLU) layer \n",
            "Epoch 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-12-02 22:53:32.272143: E tensorflow/core/util/util.cc:131] oneDNN supports DT_HALF only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n",
            "2025-12-02 22:53:32.312993: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002\n",
            "2025-12-02 22:53:34.286285: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 260.16MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
            "2025-12-02 22:53:44.503283: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:501] Allocator (GPU_0_bfc) ran out of memory trying to allocate 122.07MiB (rounded to 128000000)requested by op Mul\n",
            "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
            "Current allocation summary follows.\n",
            "Current allocation summary follows.\n",
            "2025-12-02 22:53:44.503383: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1049] BFCAllocator dump for GPU_0_bfc\n",
            "2025-12-02 22:53:44.503404: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (256): \tTotal Chunks: 74, Chunks in use: 74. 18.5KiB allocated for chunks. 18.5KiB in use in bin. 4.7KiB client-requested in use in bin.\n",
            "2025-12-02 22:53:44.503418: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (512): \tTotal Chunks: 26, Chunks in use: 26. 13.2KiB allocated for chunks. 13.2KiB in use in bin. 13.0KiB client-requested in use in bin.\n",
            "2025-12-02 22:53:44.503430: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (1024): \tTotal Chunks: 26, Chunks in use: 26. 29.2KiB allocated for chunks. 29.2KiB in use in bin. 26.1KiB client-requested in use in bin.\n",
            "2025-12-02 22:53:44.503442: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (2048): \tTotal Chunks: 202, Chunks in use: 201. 607.8KiB allocated for chunks. 604.0KiB in use in bin. 570.9KiB client-requested in use in bin.\n",
            "2025-12-02 22:53:44.503454: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (4096): \tTotal Chunks: 55, Chunks in use: 55. 264.2KiB allocated for chunks. 264.2KiB in use in bin. 203.0KiB client-requested in use in bin.\n",
            "2025-12-02 22:53:44.503465: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (8192): \tTotal Chunks: 15, Chunks in use: 15. 138.5KiB allocated for chunks. 138.5KiB in use in bin. 122.0KiB client-requested in use in bin.\n",
            "2025-12-02 22:53:44.503476: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (16384): \tTotal Chunks: 53, Chunks in use: 51. 1.31MiB allocated for chunks. 1.26MiB in use in bin. 1.25MiB client-requested in use in bin.\n",
            "2025-12-02 22:53:44.503488: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (32768): \tTotal Chunks: 14, Chunks in use: 14. 547.8KiB allocated for chunks. 547.8KiB in use in bin. 443.6KiB client-requested in use in bin.\n",
            "2025-12-02 22:53:44.503499: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (65536): \tTotal Chunks: 5, Chunks in use: 5. 461.8KiB allocated for chunks. 461.8KiB in use in bin. 326.0KiB client-requested in use in bin.\n",
            "2025-12-02 22:53:44.503511: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (131072): \tTotal Chunks: 5, Chunks in use: 4. 654.8KiB allocated for chunks. 512.0KiB in use in bin. 512.0KiB client-requested in use in bin.\n",
            "2025-12-02 22:53:44.503522: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (262144): \tTotal Chunks: 3, Chunks in use: 2. 871.0KiB allocated for chunks. 512.0KiB in use in bin. 512.0KiB client-requested in use in bin.\n",
            "2025-12-02 22:53:44.503535: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (524288): \tTotal Chunks: 4, Chunks in use: 3. 2.84MiB allocated for chunks. 2.13MiB in use in bin. 2.13MiB client-requested in use in bin.\n",
            "2025-12-02 22:53:44.503546: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (1048576): \tTotal Chunks: 1, Chunks in use: 1. 1.17MiB allocated for chunks. 1.17MiB in use in bin. 728.0KiB client-requested in use in bin.\n",
            "2025-12-02 22:53:44.503558: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (2097152): \tTotal Chunks: 56, Chunks in use: 56. 123.31MiB allocated for chunks. 123.31MiB in use in bin. 116.50MiB client-requested in use in bin.\n",
            "2025-12-02 22:53:44.503569: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (4194304): \tTotal Chunks: 2, Chunks in use: 2. 12.00MiB allocated for chunks. 12.00MiB in use in bin. 12.00MiB client-requested in use in bin.\n",
            "2025-12-02 22:53:44.503581: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (8388608): \tTotal Chunks: 5, Chunks in use: 5. 65.66MiB allocated for chunks. 65.66MiB in use in bin. 61.50MiB client-requested in use in bin.\n",
            "2025-12-02 22:53:44.503604: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (16777216): \tTotal Chunks: 11, Chunks in use: 11. 292.51MiB allocated for chunks. 292.51MiB in use in bin. 276.33MiB client-requested in use in bin.\n",
            "2025-12-02 22:53:44.503616: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (33554432): \tTotal Chunks: 3, Chunks in use: 3. 183.11MiB allocated for chunks. 183.11MiB in use in bin. 183.11MiB client-requested in use in bin.\n",
            "2025-12-02 22:53:44.503628: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (67108864): \tTotal Chunks: 1, Chunks in use: 1. 99.23MiB allocated for chunks. 99.23MiB in use in bin. 61.04MiB client-requested in use in bin.\n",
            "2025-12-02 22:53:44.503673: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (134217728): \tTotal Chunks: 1, Chunks in use: 1. 228.97MiB allocated for chunks. 228.97MiB in use in bin. 122.07MiB client-requested in use in bin.\n",
            "2025-12-02 22:53:44.503689: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1056] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2025-12-02 22:53:44.503701: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1072] Bin for 122.07MiB was 64.00MiB, Chunk State: \n",
            "2025-12-02 22:53:44.503709: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 528089088\n",
            "2025-12-02 22:53:44.503722: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749328000000 of size 64000000 next 551\n",
            "2025-12-02 22:53:44.503730: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74932bd09000 of size 64000000 next 554\n",
            "2025-12-02 22:53:44.503738: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74932fa12000 of size 32000000 next 555\n",
            "2025-12-02 22:53:44.503746: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749331896800 of size 32000000 next 556\n",
            "2025-12-02 22:53:44.503753: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74933371b000 of size 32000000 next 558\n",
            "2025-12-02 22:53:44.503759: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74933559f800 of size 64000000 next 559\n",
            "2025-12-02 22:53:44.503766: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493392a8800 of size 240089088 next 18446744073709551615\n",
            "2025-12-02 22:53:44.503773: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 268435456\n",
            "2025-12-02 22:53:44.503780: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493a0000000 of size 16777216 next 335\n",
            "2025-12-02 22:53:44.503787: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493a1000000 of size 33032192 next 538\n",
            "2025-12-02 22:53:44.503794: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493a2f80800 of size 33032192 next 541\n",
            "2025-12-02 22:53:44.503801: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493a4f01000 of size 33032192 next 544\n",
            "2025-12-02 22:53:44.503807: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493a6e81800 of size 16516096 next 545\n",
            "2025-12-02 22:53:44.503814: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493a7e41c00 of size 32000000 next 547\n",
            "2025-12-02 22:53:44.503821: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493a9cc6400 of size 104045568 next 18446744073709551615\n",
            "2025-12-02 22:53:44.503827: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 134217728\n",
            "2025-12-02 22:53:44.503834: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493bc000000 of size 2119936 next 354\n",
            "2025-12-02 22:53:44.503841: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493bc205900 of size 2119936 next 345\n",
            "2025-12-02 22:53:44.503850: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493bc40b200 of size 2119936 next 358\n",
            "2025-12-02 22:53:44.503857: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493bc610b00 of size 2119936 next 365\n",
            "2025-12-02 22:53:44.503863: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493bc816400 of size 2119936 next 371\n",
            "2025-12-02 22:53:44.503869: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493bca1bd00 of size 2119936 next 376\n",
            "2025-12-02 22:53:44.503876: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493bcc21600 of size 4057600 next 80\n",
            "2025-12-02 22:53:44.503883: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493bd000000 of size 16777216 next 111\n",
            "2025-12-02 22:53:44.503890: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493be000000 of size 2119936 next 457\n",
            "2025-12-02 22:53:44.503896: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493be205900 of size 2119936 next 463\n",
            "2025-12-02 22:53:44.503902: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493be40b200 of size 2119936 next 469\n",
            "2025-12-02 22:53:44.503909: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493be610b00 of size 2119936 next 475\n",
            "2025-12-02 22:53:44.503967: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493be816400 of size 2119936 next 480\n",
            "2025-12-02 22:53:44.503974: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493bea1bd00 of size 2119936 next 486\n",
            "2025-12-02 22:53:44.503980: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493bec21600 of size 2119936 next 490\n",
            "2025-12-02 22:53:44.503988: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493bee26f00 of size 8945664 next 497\n",
            "2025-12-02 22:53:44.503995: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493bf6aef00 of size 2981888 next 511\n",
            "2025-12-02 22:53:44.504001: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493bf986f00 of size 6291456 next 534\n",
            "2025-12-02 22:53:44.504008: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493bff86f00 of size 16516096 next 537\n",
            "2025-12-02 22:53:44.504015: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493c0f47300 of size 24214528 next 513\n",
            "2025-12-02 22:53:44.504021: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493c265ef00 of size 12582912 next 518\n",
            "2025-12-02 22:53:44.504029: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493c325ef00 of size 14291200 next 18446744073709551615\n",
            "2025-12-02 22:53:44.504035: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 67108864\n",
            "2025-12-02 22:53:44.504042: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493c4000000 of size 2119936 next 234\n",
            "2025-12-02 22:53:44.504049: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493c4205900 of size 2119936 next 240\n",
            "2025-12-02 22:53:44.504056: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493c440b200 of size 2981888 next 247\n",
            "2025-12-02 22:53:44.504062: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493c46e3200 of size 262144 next 305\n",
            "2025-12-02 22:53:44.504069: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493c4723200 of size 1228800 next 342\n",
            "2025-12-02 22:53:44.504076: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 7493c484f200 of size 745472 next 341\n",
            "2025-12-02 22:53:44.504083: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493c4905200 of size 745472 next 246\n",
            "2025-12-02 22:53:44.504090: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493c49bb200 of size 2981888 next 260\n",
            "2025-12-02 22:53:44.504099: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493c4c93200 of size 21856256 next 270\n",
            "2025-12-02 22:53:44.504106: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493c616b200 of size 6291456 next 73\n",
            "2025-12-02 22:53:44.504112: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493c676b200 of size 2119936 next 385\n",
            "2025-12-02 22:53:44.504119: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493c6970b00 of size 2119936 next 391\n",
            "2025-12-02 22:53:44.504125: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493c6b76400 of size 2119936 next 399\n",
            "2025-12-02 22:53:44.504131: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493c6d7bd00 of size 2119936 next 404\n",
            "2025-12-02 22:53:44.504138: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493c6f81600 of size 2119936 next 410\n",
            "2025-12-02 22:53:44.504144: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493c7186f00 of size 2119936 next 416\n",
            "2025-12-02 22:53:44.504151: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493c738c800 of size 2119936 next 422\n",
            "2025-12-02 22:53:44.504157: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493c7592100 of size 2119936 next 428\n",
            "2025-12-02 22:53:44.504163: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493c7797a00 of size 2119936 next 434\n",
            "2025-12-02 22:53:44.504170: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493c799d300 of size 2119936 next 440\n",
            "2025-12-02 22:53:44.504176: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493c7ba2c00 of size 2119936 next 446\n",
            "2025-12-02 22:53:44.504183: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493c7da8500 of size 2456320 next 18446744073709551615\n",
            "2025-12-02 22:53:44.504189: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 33554432\n",
            "2025-12-02 22:53:44.504196: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493e2000000 of size 2119936 next 145\n",
            "2025-12-02 22:53:44.504202: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493e2205900 of size 2119936 next 151\n",
            "2025-12-02 22:53:44.504209: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493e240b200 of size 2119936 next 157\n",
            "2025-12-02 22:53:44.504215: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493e2610b00 of size 2119936 next 163\n",
            "2025-12-02 22:53:44.504221: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493e2816400 of size 2119936 next 169\n",
            "2025-12-02 22:53:44.504228: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493e2a1bd00 of size 2119936 next 175\n",
            "2025-12-02 22:53:44.504234: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493e2c21600 of size 2119936 next 181\n",
            "2025-12-02 22:53:44.504240: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493e2e26f00 of size 2119936 next 187\n",
            "2025-12-02 22:53:44.504247: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493e302c800 of size 2119936 next 192\n",
            "2025-12-02 22:53:44.504253: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493e3232100 of size 2119936 next 198\n",
            "2025-12-02 22:53:44.504260: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493e3437a00 of size 2119936 next 204\n",
            "2025-12-02 22:53:44.504266: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493e363d300 of size 2119936 next 210\n",
            "2025-12-02 22:53:44.504272: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493e3842c00 of size 2119936 next 216\n",
            "2025-12-02 22:53:44.504279: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493e3a48500 of size 2119936 next 222\n",
            "2025-12-02 22:53:44.504288: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7493e3c4de00 of size 3875328 next 18446744073709551615\n",
            "2025-12-02 22:53:44.504294: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 2097152\n",
            "2025-12-02 22:53:44.504301: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436600000 of size 1280 next 1\n",
            "2025-12-02 22:53:44.504308: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436600500 of size 256 next 2\n",
            "2025-12-02 22:53:44.504315: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436600600 of size 256 next 3\n",
            "2025-12-02 22:53:44.504321: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436600700 of size 256 next 4\n",
            "2025-12-02 22:53:44.504327: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436600800 of size 256 next 5\n",
            "2025-12-02 22:53:44.504334: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436600900 of size 256 next 7\n",
            "2025-12-02 22:53:44.504340: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436600a00 of size 256 next 8\n",
            "2025-12-02 22:53:44.504347: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436600b00 of size 256 next 6\n",
            "2025-12-02 22:53:44.504353: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436600c00 of size 256 next 9\n",
            "2025-12-02 22:53:44.504359: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436600d00 of size 256 next 12\n",
            "2025-12-02 22:53:44.504366: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436600e00 of size 256 next 13\n",
            "2025-12-02 22:53:44.504372: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436600f00 of size 256 next 14\n",
            "2025-12-02 22:53:44.504379: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436601000 of size 256 next 15\n",
            "2025-12-02 22:53:44.504385: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436601100 of size 256 next 18\n",
            "2025-12-02 22:53:44.504391: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436601200 of size 256 next 16\n",
            "2025-12-02 22:53:44.504398: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436601300 of size 256 next 17\n",
            "2025-12-02 22:53:44.504404: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436601400 of size 256 next 21\n",
            "2025-12-02 22:53:44.504410: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436601500 of size 256 next 22\n",
            "2025-12-02 22:53:44.504417: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436601600 of size 512 next 23\n",
            "2025-12-02 22:53:44.504424: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436601800 of size 512 next 26\n",
            "2025-12-02 22:53:44.504430: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436601a00 of size 512 next 24\n",
            "2025-12-02 22:53:44.504437: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436601c00 of size 256 next 257\n",
            "2025-12-02 22:53:44.504443: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436601d00 of size 256 next 25\n",
            "2025-12-02 22:53:44.504450: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436601e00 of size 256 next 29\n",
            "2025-12-02 22:53:44.504456: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436601f00 of size 256 next 30\n",
            "2025-12-02 22:53:44.504462: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436602000 of size 512 next 34\n",
            "2025-12-02 22:53:44.504469: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436602200 of size 512 next 32\n",
            "2025-12-02 22:53:44.504475: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436602400 of size 512 next 31\n",
            "2025-12-02 22:53:44.504483: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436602600 of size 512 next 10\n",
            "2025-12-02 22:53:44.504490: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436602800 of size 256 next 282\n",
            "2025-12-02 22:53:44.504496: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436602900 of size 3328 next 11\n",
            "2025-12-02 22:53:44.504503: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436603600 of size 1024 next 51\n",
            "2025-12-02 22:53:44.504509: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436603a00 of size 1024 next 52\n",
            "2025-12-02 22:53:44.504516: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436603e00 of size 256 next 271\n",
            "2025-12-02 22:53:44.504522: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436603f00 of size 256 next 125\n",
            "2025-12-02 22:53:44.504529: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436604000 of size 256 next 290\n",
            "2025-12-02 22:53:44.504535: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436604100 of size 256 next 53\n",
            "2025-12-02 22:53:44.504541: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436604200 of size 256 next 62\n",
            "2025-12-02 22:53:44.504548: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436604300 of size 256 next 63\n",
            "2025-12-02 22:53:44.504554: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436604400 of size 256 next 64\n",
            "2025-12-02 22:53:44.504560: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436604500 of size 256 next 65\n",
            "2025-12-02 22:53:44.504567: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436604600 of size 1024 next 66\n",
            "2025-12-02 22:53:44.504573: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436604a00 of size 1024 next 71\n",
            "2025-12-02 22:53:44.504580: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436604e00 of size 1024 next 69\n",
            "2025-12-02 22:53:44.504586: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436605200 of size 1024 next 70\n",
            "2025-12-02 22:53:44.504592: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436605600 of size 256 next 74\n",
            "2025-12-02 22:53:44.504599: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436605700 of size 256 next 87\n",
            "2025-12-02 22:53:44.504605: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436605800 of size 256 next 76\n",
            "2025-12-02 22:53:44.504612: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436605900 of size 256 next 44\n",
            "2025-12-02 22:53:44.504619: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436605a00 of size 4608 next 43\n",
            "2025-12-02 22:53:44.504625: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436606c00 of size 1024 next 58\n",
            "2025-12-02 22:53:44.504632: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436607000 of size 1024 next 56\n",
            "2025-12-02 22:53:44.504654: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436607400 of size 1024 next 57\n",
            "2025-12-02 22:53:44.504661: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436607800 of size 1024 next 289\n",
            "2025-12-02 22:53:44.504668: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436607c00 of size 5376 next 61\n",
            "2025-12-02 22:53:44.504675: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436609100 of size 3072 next 77\n",
            "2025-12-02 22:53:44.504681: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436609d00 of size 3072 next 84\n",
            "2025-12-02 22:53:44.504688: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943660a900 of size 3328 next 37\n",
            "2025-12-02 22:53:44.504697: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943660b600 of size 32768 next 28\n",
            "2025-12-02 22:53:44.504703: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436613600 of size 32768 next 27\n",
            "2025-12-02 22:53:44.504710: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943661b600 of size 256 next 33\n",
            "2025-12-02 22:53:44.504716: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943661b700 of size 256 next 38\n",
            "2025-12-02 22:53:44.504723: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943661b800 of size 256 next 39\n",
            "2025-12-02 22:53:44.504729: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943661b900 of size 256 next 42\n",
            "2025-12-02 22:53:44.504735: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943661ba00 of size 512 next 40\n",
            "2025-12-02 22:53:44.504742: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943661bc00 of size 512 next 46\n",
            "2025-12-02 22:53:44.504748: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943661be00 of size 512 next 41\n",
            "2025-12-02 22:53:44.504755: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943661c000 of size 512 next 45\n",
            "2025-12-02 22:53:44.504761: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943661c200 of size 256 next 49\n",
            "2025-12-02 22:53:44.504768: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943661c300 of size 256 next 50\n",
            "2025-12-02 22:53:44.504774: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943661c400 of size 1024 next 36\n",
            "2025-12-02 22:53:44.504781: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943661c800 of size 512 next 284\n",
            "2025-12-02 22:53:44.504788: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943661ca00 of size 1792 next 35\n",
            "2025-12-02 22:53:44.504794: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943661d100 of size 3072 next 75\n",
            "2025-12-02 22:53:44.504801: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943661dd00 of size 3072 next 79\n",
            "2025-12-02 22:53:44.504807: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943661e900 of size 3072 next 68\n",
            "2025-12-02 22:53:44.504814: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943661f500 of size 9216 next 67\n",
            "2025-12-02 22:53:44.504821: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436621900 of size 3072 next 82\n",
            "2025-12-02 22:53:44.504827: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436622500 of size 3072 next 83\n",
            "2025-12-02 22:53:44.504834: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436623100 of size 256 next 88\n",
            "2025-12-02 22:53:44.504841: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436623200 of size 256 next 91\n",
            "2025-12-02 22:53:44.504848: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436623300 of size 3072 next 89\n",
            "2025-12-02 22:53:44.504854: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436623f00 of size 3072 next 96\n",
            "2025-12-02 22:53:44.504860: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436624b00 of size 3072 next 90\n",
            "2025-12-02 22:53:44.504867: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436625700 of size 3072 next 94\n",
            "2025-12-02 22:53:44.504873: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436626300 of size 4864 next 20\n",
            "2025-12-02 22:53:44.504880: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436627600 of size 32768 next 283\n",
            "2025-12-02 22:53:44.504887: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943662f600 of size 26368 next 119\n",
            "2025-12-02 22:53:44.504894: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436635d00 of size 50176 next 102\n",
            "2025-12-02 22:53:44.504901: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436642100 of size 26368 next 93\n",
            "2025-12-02 22:53:44.504907: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436648800 of size 26368 next 92\n",
            "2025-12-02 22:53:44.504948: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943664ef00 of size 3072 next 124\n",
            "2025-12-02 22:53:44.504955: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943664fb00 of size 3072 next 122\n",
            "2025-12-02 22:53:44.504962: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436650700 of size 3072 next 126\n",
            "2025-12-02 22:53:44.504968: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436651300 of size 3072 next 129\n",
            "2025-12-02 22:53:44.504975: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436651f00 of size 3072 next 123\n",
            "2025-12-02 22:53:44.504982: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436652b00 of size 3072 next 130\n",
            "2025-12-02 22:53:44.504988: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436653700 of size 3072 next 128\n",
            "2025-12-02 22:53:44.504995: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436654300 of size 3072 next 135\n",
            "2025-12-02 22:53:44.505001: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436654f00 of size 3072 next 133\n",
            "2025-12-02 22:53:44.505007: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436655b00 of size 3072 next 134\n",
            "2025-12-02 22:53:44.505014: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436656700 of size 3072 next 138\n",
            "2025-12-02 22:53:44.505020: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436657300 of size 3072 next 142\n",
            "2025-12-02 22:53:44.505027: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436657f00 of size 5888 next 48\n",
            "2025-12-02 22:53:44.505034: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436659600 of size 26368 next 109\n",
            "2025-12-02 22:53:44.505041: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943665fd00 of size 3072 next 107\n",
            "2025-12-02 22:53:44.505052: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436660900 of size 3072 next 105\n",
            "2025-12-02 22:53:44.505058: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436661500 of size 3072 next 47\n",
            "2025-12-02 22:53:44.505065: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436662100 of size 3072 next 113\n",
            "2025-12-02 22:53:44.505072: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436662d00 of size 36096 next 115\n",
            "2025-12-02 22:53:44.505079: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943666ba00 of size 3072 next 118\n",
            "2025-12-02 22:53:44.505085: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943666c600 of size 3072 next 112\n",
            "2025-12-02 22:53:44.505091: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943666d200 of size 3072 next 120\n",
            "2025-12-02 22:53:44.505098: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943666de00 of size 3072 next 117\n",
            "2025-12-02 22:53:44.505104: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943666ea00 of size 4864 next 108\n",
            "2025-12-02 22:53:44.505111: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943666fd00 of size 3072 next 101\n",
            "2025-12-02 22:53:44.505117: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436670900 of size 3072 next 106\n",
            "2025-12-02 22:53:44.505124: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436671500 of size 3072 next 99\n",
            "2025-12-02 22:53:44.505131: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436672100 of size 3072 next 72\n",
            "2025-12-02 22:53:44.505138: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436672d00 of size 40448 next 114\n",
            "2025-12-02 22:53:44.505145: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943667cb00 of size 51968 next 54\n",
            "2025-12-02 22:53:44.505152: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436689600 of size 26368 next 140\n",
            "2025-12-02 22:53:44.505159: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943668fd00 of size 36864 next 155\n",
            "2025-12-02 22:53:44.505166: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436698d00 of size 67840 next 55\n",
            "2025-12-02 22:53:44.505173: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366a9600 of size 131072 next 59\n",
            "2025-12-02 22:53:44.505180: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366c9600 of size 3072 next 200\n",
            "2025-12-02 22:53:44.505186: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366ca200 of size 3072 next 201\n",
            "2025-12-02 22:53:44.505193: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366cae00 of size 3072 next 207\n",
            "2025-12-02 22:53:44.505199: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366cba00 of size 3072 next 205\n",
            "2025-12-02 22:53:44.505205: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366cc600 of size 3072 next 206\n",
            "2025-12-02 22:53:44.505212: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366cd200 of size 3072 next 211\n",
            "2025-12-02 22:53:44.505218: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366cde00 of size 3072 next 214\n",
            "2025-12-02 22:53:44.505225: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366cea00 of size 4864 next 197\n",
            "2025-12-02 22:53:44.505231: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366cfd00 of size 26368 next 196\n",
            "2025-12-02 22:53:44.505237: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366d6400 of size 26368 next 203\n",
            "2025-12-02 22:53:44.505244: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366dcb00 of size 3072 next 212\n",
            "2025-12-02 22:53:44.505250: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366dd700 of size 3072 next 213\n",
            "2025-12-02 22:53:44.505257: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366de300 of size 3072 next 219\n",
            "2025-12-02 22:53:44.505264: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366def00 of size 3072 next 217\n",
            "2025-12-02 22:53:44.505270: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366dfb00 of size 3072 next 218\n",
            "2025-12-02 22:53:44.505276: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366e0700 of size 3072 next 223\n",
            "2025-12-02 22:53:44.505283: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366e1300 of size 3072 next 226\n",
            "2025-12-02 22:53:44.505290: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366e1f00 of size 4864 next 209\n",
            "2025-12-02 22:53:44.505296: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366e3200 of size 26368 next 208\n",
            "2025-12-02 22:53:44.505303: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366e9900 of size 26368 next 215\n",
            "2025-12-02 22:53:44.505309: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366f0000 of size 3072 next 224\n",
            "2025-12-02 22:53:44.505316: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366f0c00 of size 3072 next 225\n",
            "2025-12-02 22:53:44.505322: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366f1800 of size 3072 next 230\n",
            "2025-12-02 22:53:44.505329: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366f2400 of size 3072 next 228\n",
            "2025-12-02 22:53:44.505335: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366f3000 of size 3072 next 229\n",
            "2025-12-02 22:53:44.505342: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366f3c00 of size 3072 next 235\n",
            "2025-12-02 22:53:44.505349: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366f4800 of size 3072 next 238\n",
            "2025-12-02 22:53:44.505355: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366f5400 of size 4864 next 221\n",
            "2025-12-02 22:53:44.505362: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366f6700 of size 26368 next 220\n",
            "2025-12-02 22:53:44.505368: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494366fce00 of size 26368 next 227\n",
            "2025-12-02 22:53:44.505375: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436703500 of size 3072 next 236\n",
            "2025-12-02 22:53:44.505381: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436704100 of size 3072 next 237\n",
            "2025-12-02 22:53:44.505388: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436704d00 of size 256 next 241\n",
            "2025-12-02 22:53:44.505395: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436704e00 of size 256 next 242\n",
            "2025-12-02 22:53:44.505401: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436704f00 of size 4096 next 243\n",
            "2025-12-02 22:53:44.505408: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436705f00 of size 4096 next 244\n",
            "2025-12-02 22:53:44.505415: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436706f00 of size 4096 next 245\n",
            "2025-12-02 22:53:44.505422: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436707f00 of size 7424 next 232\n",
            "2025-12-02 22:53:44.505428: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436709c00 of size 26368 next 231\n",
            "2025-12-02 22:53:44.505435: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436710300 of size 26368 next 239\n",
            "2025-12-02 22:53:44.505441: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436716a00 of size 3072 next 250\n",
            "2025-12-02 22:53:44.505448: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436717600 of size 3072 next 248\n",
            "2025-12-02 22:53:44.505454: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436718200 of size 3072 next 249\n",
            "2025-12-02 22:53:44.505461: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436718e00 of size 7168 next 256\n",
            "2025-12-02 22:53:44.505468: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943671aa00 of size 4096 next 254\n",
            "2025-12-02 22:53:44.505475: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943671ba00 of size 6144 next 252\n",
            "2025-12-02 22:53:44.505482: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943671d200 of size 26368 next 253\n",
            "2025-12-02 22:53:44.505488: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436723900 of size 4096 next 255\n",
            "2025-12-02 22:53:44.505495: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436724900 of size 256 next 261\n",
            "2025-12-02 22:53:44.505502: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436724a00 of size 256 next 262\n",
            "2025-12-02 22:53:44.505508: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436724b00 of size 256 next 263\n",
            "2025-12-02 22:53:44.505514: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436724c00 of size 256 next 264\n",
            "2025-12-02 22:53:44.505521: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436724d00 of size 6144 next 265\n",
            "2025-12-02 22:53:44.505528: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436726500 of size 6144 next 269\n",
            "2025-12-02 22:53:44.505535: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436727d00 of size 8960 next 258\n",
            "2025-12-02 22:53:44.505541: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943672a000 of size 4096 next 259\n",
            "2025-12-02 22:53:44.505548: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943672b000 of size 8192 next 281\n",
            "2025-12-02 22:53:44.505555: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943672d000 of size 8192 next 267\n",
            "2025-12-02 22:53:44.505561: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943672f000 of size 256 next 292\n",
            "2025-12-02 22:53:44.505568: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943672f100 of size 256 next 291\n",
            "2025-12-02 22:53:44.505574: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943672f200 of size 256 next 296\n",
            "2025-12-02 22:53:44.505581: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943672f300 of size 256 next 297\n",
            "2025-12-02 22:53:44.505587: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943672f400 of size 256 next 298\n",
            "2025-12-02 22:53:44.505594: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943672f500 of size 768 next 302\n",
            "2025-12-02 22:53:44.505601: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943672f800 of size 512 next 303\n",
            "2025-12-02 22:53:44.505608: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943672fa00 of size 512 next 301\n",
            "2025-12-02 22:53:44.505614: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943672fc00 of size 256 next 501\n",
            "2025-12-02 22:53:44.505621: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943672fd00 of size 256 next 306\n",
            "2025-12-02 22:53:44.505627: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943672fe00 of size 512 next 316\n",
            "2025-12-02 22:53:44.505634: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436730000 of size 512 next 314\n",
            "2025-12-02 22:53:44.505654: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436730200 of size 512 next 315\n",
            "2025-12-02 22:53:44.505661: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436730400 of size 1024 next 321\n",
            "2025-12-02 22:53:44.505668: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436730800 of size 1536 next 295\n",
            "2025-12-02 22:53:44.505675: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436730e00 of size 256 next 527\n",
            "2025-12-02 22:53:44.505681: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436730f00 of size 4096 next 266\n",
            "2025-12-02 22:53:44.505688: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436731f00 of size 256 next 268\n",
            "2025-12-02 22:53:44.505694: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436732000 of size 256 next 272\n",
            "2025-12-02 22:53:44.505702: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436732100 of size 256 next 273\n",
            "2025-12-02 22:53:44.505708: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436732200 of size 256 next 276\n",
            "2025-12-02 22:53:44.505714: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436732300 of size 8192 next 274\n",
            "2025-12-02 22:53:44.505721: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436734300 of size 8192 next 275\n",
            "2025-12-02 22:53:44.505728: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436736300 of size 512 next 309\n",
            "2025-12-02 22:53:44.505734: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436736500 of size 512 next 307\n",
            "2025-12-02 22:53:44.505741: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436736700 of size 512 next 308\n",
            "2025-12-02 22:53:44.505747: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436736900 of size 512 next 310\n",
            "2025-12-02 22:53:44.505754: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436736b00 of size 512 next 311\n",
            "2025-12-02 22:53:44.505760: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436736d00 of size 512 next 300\n",
            "2025-12-02 22:53:44.505767: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436736f00 of size 1792 next 312\n",
            "2025-12-02 22:53:44.505773: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436737600 of size 1024 next 322\n",
            "2025-12-02 22:53:44.505780: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436737a00 of size 4096 next 338\n",
            "2025-12-02 22:53:44.505786: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436738a00 of size 4096 next 318\n",
            "2025-12-02 22:53:44.505793: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436739a00 of size 4608 next 317\n",
            "2025-12-02 22:53:44.505799: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943673ac00 of size 1024 next 333\n",
            "2025-12-02 22:53:44.505805: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943673b000 of size 1024 next 334\n",
            "2025-12-02 22:53:44.505812: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943673b400 of size 1024 next 331\n",
            "2025-12-02 22:53:44.505818: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943673b800 of size 1792 next 329\n",
            "2025-12-02 22:53:44.505824: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943673bf00 of size 1024 next 330\n",
            "2025-12-02 22:53:44.505831: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943673c300 of size 1024 next 327\n",
            "2025-12-02 22:53:44.505837: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943673c700 of size 1024 next 325\n",
            "2025-12-02 22:53:44.505843: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943673cb00 of size 9216 next 326\n",
            "2025-12-02 22:53:44.505850: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943673ef00 of size 29696 next 304\n",
            "2025-12-02 22:53:44.505857: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436746300 of size 3072 next 339\n",
            "2025-12-02 22:53:44.505864: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436746f00 of size 3072 next 340\n",
            "2025-12-02 22:53:44.505870: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436747b00 of size 3072 next 343\n",
            "2025-12-02 22:53:44.505877: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436748700 of size 3072 next 350\n",
            "2025-12-02 22:53:44.505883: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436749300 of size 3072 next 351\n",
            "2025-12-02 22:53:44.505890: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436749f00 of size 3072 next 336\n",
            "2025-12-02 22:53:44.505896: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943674ab00 of size 1024 next 530\n",
            "2025-12-02 22:53:44.505904: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943674af00 of size 13312 next 313\n",
            "2025-12-02 22:53:44.505930: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943674e300 of size 4608 next 528\n",
            "2025-12-02 22:53:44.505938: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943674f500 of size 118272 next 299\n",
            "2025-12-02 22:53:44.505945: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943676c300 of size 3072 next 356\n",
            "2025-12-02 22:53:44.505952: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943676cf00 of size 3072 next 362\n",
            "2025-12-02 22:53:44.505959: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943676db00 of size 3072 next 360\n",
            "2025-12-02 22:53:44.505965: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943676e700 of size 3072 next 361\n",
            "2025-12-02 22:53:44.505972: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943676f300 of size 3072 next 366\n",
            "2025-12-02 22:53:44.505979: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943676ff00 of size 3072 next 369\n",
            "2025-12-02 22:53:44.505985: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436770b00 of size 3072 next 367\n",
            "2025-12-02 22:53:44.505991: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436771700 of size 4864 next 359\n",
            "2025-12-02 22:53:44.505999: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436772a00 of size 26368 next 353\n",
            "2025-12-02 22:53:44.506005: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436779100 of size 26368 next 352\n",
            "2025-12-02 22:53:44.506011: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943677f800 of size 3072 next 379\n",
            "2025-12-02 22:53:44.506018: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436780400 of size 3072 next 384\n",
            "2025-12-02 22:53:44.506025: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436781000 of size 3072 next 382\n",
            "2025-12-02 22:53:44.506031: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436781c00 of size 3072 next 383\n",
            "2025-12-02 22:53:44.506038: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436782800 of size 3072 next 387\n",
            "2025-12-02 22:53:44.506045: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436783400 of size 3072 next 390\n",
            "2025-12-02 22:53:44.506051: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436784000 of size 3072 next 388\n",
            "2025-12-02 22:53:44.506057: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436784c00 of size 3072 next 389\n",
            "2025-12-02 22:53:44.506064: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436785800 of size 3072 next 393\n",
            "2025-12-02 22:53:44.506071: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436786400 of size 3072 next 396\n",
            "2025-12-02 22:53:44.506077: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436787000 of size 3072 next 394\n",
            "2025-12-02 22:53:44.506083: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436787c00 of size 3072 next 395\n",
            "2025-12-02 22:53:44.506090: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436788800 of size 3072 next 400\n",
            "2025-12-02 22:53:44.506097: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436789400 of size 3072 next 403\n",
            "2025-12-02 22:53:44.506103: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943678a000 of size 3072 next 401\n",
            "2025-12-02 22:53:44.506109: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943678ac00 of size 5888 next 320\n",
            "2025-12-02 22:53:44.506116: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943678c300 of size 32768 next 529\n",
            "2025-12-02 22:53:44.506122: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436794300 of size 26368 next 324\n",
            "2025-12-02 22:53:44.506129: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943679aa00 of size 34816 next 137\n",
            "2025-12-02 22:53:44.506137: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367a3200 of size 26368 next 136\n",
            "2025-12-02 22:53:44.506143: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367a9900 of size 3072 next 131\n",
            "2025-12-02 22:53:44.506150: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367aa500 of size 3072 next 98\n",
            "2025-12-02 22:53:44.506159: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367ab100 of size 3072 next 141\n",
            "2025-12-02 22:53:44.506165: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367abd00 of size 3072 next 148\n",
            "2025-12-02 22:53:44.506172: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367ac900 of size 3072 next 146\n",
            "2025-12-02 22:53:44.506178: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367ad500 of size 3072 next 147\n",
            "2025-12-02 22:53:44.506185: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367ae100 of size 3072 next 152\n",
            "2025-12-02 22:53:44.506192: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367aed00 of size 4864 next 143\n",
            "2025-12-02 22:53:44.506198: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367b0000 of size 3072 next 153\n",
            "2025-12-02 22:53:44.506205: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367b0c00 of size 3072 next 154\n",
            "2025-12-02 22:53:44.506211: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367b1800 of size 3072 next 160\n",
            "2025-12-02 22:53:44.506218: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367b2400 of size 3072 next 158\n",
            "2025-12-02 22:53:44.506224: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367b3000 of size 3072 next 159\n",
            "2025-12-02 22:53:44.506231: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367b3c00 of size 3072 next 164\n",
            "2025-12-02 22:53:44.506237: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367b4800 of size 3072 next 167\n",
            "2025-12-02 22:53:44.506244: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367b5400 of size 4864 next 150\n",
            "2025-12-02 22:53:44.506250: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367b6700 of size 26368 next 149\n",
            "2025-12-02 22:53:44.506257: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367bce00 of size 26368 next 156\n",
            "2025-12-02 22:53:44.506264: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367c3500 of size 3072 next 165\n",
            "2025-12-02 22:53:44.506270: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367c4100 of size 3072 next 166\n",
            "2025-12-02 22:53:44.506277: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367c4d00 of size 3072 next 172\n",
            "2025-12-02 22:53:44.506283: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367c5900 of size 3072 next 170\n",
            "2025-12-02 22:53:44.506290: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367c6500 of size 3072 next 171\n",
            "2025-12-02 22:53:44.506296: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367c7100 of size 3072 next 176\n",
            "2025-12-02 22:53:44.506303: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367c7d00 of size 3072 next 179\n",
            "2025-12-02 22:53:44.506310: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367c8900 of size 4864 next 162\n",
            "2025-12-02 22:53:44.506316: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367c9c00 of size 26368 next 161\n",
            "2025-12-02 22:53:44.506323: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367d0300 of size 26368 next 168\n",
            "2025-12-02 22:53:44.506331: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367d6a00 of size 3072 next 177\n",
            "2025-12-02 22:53:44.506338: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367d7600 of size 3072 next 178\n",
            "2025-12-02 22:53:44.506344: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367d8200 of size 3072 next 184\n",
            "2025-12-02 22:53:44.506351: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367d8e00 of size 3072 next 182\n",
            "2025-12-02 22:53:44.506358: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367d9a00 of size 3072 next 183\n",
            "2025-12-02 22:53:44.506364: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367da600 of size 3072 next 188\n",
            "2025-12-02 22:53:44.506371: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367db200 of size 3072 next 191\n",
            "2025-12-02 22:53:44.506377: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367dbe00 of size 4864 next 174\n",
            "2025-12-02 22:53:44.506385: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367dd100 of size 26368 next 173\n",
            "2025-12-02 22:53:44.506391: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367e3800 of size 26368 next 180\n",
            "2025-12-02 22:53:44.506397: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367e9f00 of size 3072 next 189\n",
            "2025-12-02 22:53:44.506405: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367eab00 of size 3072 next 190\n",
            "2025-12-02 22:53:44.506411: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367eb700 of size 3072 next 195\n",
            "2025-12-02 22:53:44.506418: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367ec300 of size 3072 next 193\n",
            "2025-12-02 22:53:44.506424: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367ecf00 of size 3072 next 194\n",
            "2025-12-02 22:53:44.506431: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367edb00 of size 3072 next 199\n",
            "2025-12-02 22:53:44.506438: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367ee700 of size 3072 next 202\n",
            "2025-12-02 22:53:44.506444: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367ef300 of size 4864 next 186\n",
            "2025-12-02 22:53:44.506451: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367f0600 of size 26368 next 185\n",
            "2025-12-02 22:53:44.506458: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367f6d00 of size 8192 next 279\n",
            "2025-12-02 22:53:44.506465: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367f8d00 of size 3584 next 280\n",
            "2025-12-02 22:53:44.506473: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367f9b00 of size 4608 next 285\n",
            "2025-12-02 22:53:44.506480: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367fad00 of size 9216 next 60\n",
            "2025-12-02 22:53:44.506486: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367fd100 of size 3072 next 85\n",
            "2025-12-02 22:53:44.506493: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367fdd00 of size 3072 next 100\n",
            "2025-12-02 22:53:44.506500: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494367fe900 of size 5888 next 18446744073709551615\n",
            "2025-12-02 22:53:44.506506: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 4194304\n",
            "2025-12-02 22:53:44.506513: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436c00000 of size 745472 next 19\n",
            "2025-12-02 22:53:44.506520: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436cb6000 of size 745472 next 81\n",
            "2025-12-02 22:53:44.506527: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d6c000 of size 3072 next 413\n",
            "2025-12-02 22:53:44.506534: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d6cc00 of size 3072 next 419\n",
            "2025-12-02 22:53:44.506540: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d6d800 of size 3072 next 417\n",
            "2025-12-02 22:53:44.506546: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d6e400 of size 3072 next 418\n",
            "2025-12-02 22:53:44.506555: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d6f000 of size 3072 next 423\n",
            "2025-12-02 22:53:44.506561: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d6fc00 of size 3072 next 426\n",
            "2025-12-02 22:53:44.506567: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d70800 of size 3072 next 424\n",
            "2025-12-02 22:53:44.506574: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d71400 of size 4864 next 409\n",
            "2025-12-02 22:53:44.506581: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d72700 of size 26368 next 408\n",
            "2025-12-02 22:53:44.506588: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d78e00 of size 26368 next 415\n",
            "2025-12-02 22:53:44.506594: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d7f500 of size 3072 next 425\n",
            "2025-12-02 22:53:44.506601: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d80100 of size 3072 next 431\n",
            "2025-12-02 22:53:44.506608: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d80d00 of size 3072 next 429\n",
            "2025-12-02 22:53:44.506614: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d81900 of size 3072 next 430\n",
            "2025-12-02 22:53:44.506621: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d82500 of size 3072 next 435\n",
            "2025-12-02 22:53:44.506628: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d83100 of size 3072 next 438\n",
            "2025-12-02 22:53:44.506634: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d83d00 of size 3072 next 436\n",
            "2025-12-02 22:53:44.506687: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d84900 of size 4864 next 421\n",
            "2025-12-02 22:53:44.506695: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d85c00 of size 26368 next 420\n",
            "2025-12-02 22:53:44.506702: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d8c300 of size 26368 next 427\n",
            "2025-12-02 22:53:44.506709: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d92a00 of size 3072 next 437\n",
            "2025-12-02 22:53:44.506715: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d93600 of size 3072 next 443\n",
            "2025-12-02 22:53:44.506721: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d94200 of size 3072 next 441\n",
            "2025-12-02 22:53:44.506728: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d94e00 of size 3072 next 442\n",
            "2025-12-02 22:53:44.506735: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d95a00 of size 3072 next 447\n",
            "2025-12-02 22:53:44.506741: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d96600 of size 3072 next 450\n",
            "2025-12-02 22:53:44.506748: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d97200 of size 3072 next 448\n",
            "2025-12-02 22:53:44.506755: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d97e00 of size 4864 next 433\n",
            "2025-12-02 22:53:44.506762: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d99100 of size 26368 next 432\n",
            "2025-12-02 22:53:44.506768: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436d9f800 of size 26368 next 439\n",
            "2025-12-02 22:53:44.506775: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436da5f00 of size 3072 next 449\n",
            "2025-12-02 22:53:44.506782: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436da6b00 of size 3072 next 454\n",
            "2025-12-02 22:53:44.506788: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436da7700 of size 3072 next 452\n",
            "2025-12-02 22:53:44.506795: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436da8300 of size 3072 next 453\n",
            "2025-12-02 22:53:44.506801: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436da8f00 of size 3072 next 458\n",
            "2025-12-02 22:53:44.506808: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436da9b00 of size 3072 next 461\n",
            "2025-12-02 22:53:44.506815: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436daa700 of size 3072 next 459\n",
            "2025-12-02 22:53:44.506822: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436dab300 of size 4864 next 445\n",
            "2025-12-02 22:53:44.506828: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436dac600 of size 26368 next 444\n",
            "2025-12-02 22:53:44.506835: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436db2d00 of size 26368 next 451\n",
            "2025-12-02 22:53:44.506842: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436db9400 of size 3072 next 460\n",
            "2025-12-02 22:53:44.506848: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436dba000 of size 3072 next 466\n",
            "2025-12-02 22:53:44.506855: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436dbac00 of size 3072 next 464\n",
            "2025-12-02 22:53:44.506862: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436dbb800 of size 3072 next 465\n",
            "2025-12-02 22:53:44.506869: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436dbc400 of size 3072 next 470\n",
            "2025-12-02 22:53:44.506875: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436dbd000 of size 3072 next 473\n",
            "2025-12-02 22:53:44.506881: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436dbdc00 of size 3072 next 471\n",
            "2025-12-02 22:53:44.506888: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436dbe800 of size 4864 next 456\n",
            "2025-12-02 22:53:44.506896: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436dbfb00 of size 26368 next 455\n",
            "2025-12-02 22:53:44.506903: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436dc6200 of size 26368 next 462\n",
            "2025-12-02 22:53:44.506909: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436dcc900 of size 3072 next 472\n",
            "2025-12-02 22:53:44.506938: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436dcd500 of size 3072 next 478\n",
            "2025-12-02 22:53:44.506946: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436dce100 of size 3072 next 476\n",
            "2025-12-02 22:53:44.506952: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436dced00 of size 3072 next 477\n",
            "2025-12-02 22:53:44.506959: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436dcf900 of size 3072 next 481\n",
            "2025-12-02 22:53:44.506965: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436dd0500 of size 3072 next 484\n",
            "2025-12-02 22:53:44.506971: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436dd1100 of size 3072 next 482\n",
            "2025-12-02 22:53:44.506974: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436dd1d00 of size 4864 next 468\n",
            "2025-12-02 22:53:44.506976: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436dd3000 of size 26368 next 467\n",
            "2025-12-02 22:53:44.506980: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436dd9700 of size 26368 next 474\n",
            "2025-12-02 22:53:44.506982: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ddfe00 of size 3584 next 526\n",
            "2025-12-02 22:53:44.506985: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436de0c00 of size 46080 next 337\n",
            "2025-12-02 22:53:44.506987: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 749436dec000 of size 367616 next 503\n",
            "2025-12-02 22:53:44.506990: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e45c00 of size 26368 next 502\n",
            "2025-12-02 22:53:44.506993: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e4c300 of size 6144 next 514\n",
            "2025-12-02 22:53:44.506996: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e4db00 of size 6144 next 512\n",
            "2025-12-02 22:53:44.506998: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e4f300 of size 6144 next 517\n",
            "2025-12-02 22:53:44.507000: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e50b00 of size 256 next 540\n",
            "2025-12-02 22:53:44.507003: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e50c00 of size 256 next 542\n",
            "2025-12-02 22:53:44.507006: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e50d00 of size 256 next 543\n",
            "2025-12-02 22:53:44.507008: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e50e00 of size 256 next 548\n",
            "2025-12-02 22:53:44.507011: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e50f00 of size 256 next 549\n",
            "2025-12-02 22:53:44.507013: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e51000 of size 256 next 552\n",
            "2025-12-02 22:53:44.507016: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e51100 of size 256 next 553\n",
            "2025-12-02 22:53:44.507019: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e51200 of size 1280 next 557\n",
            "2025-12-02 22:53:44.507022: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e51700 of size 512 next 560\n",
            "2025-12-02 22:53:44.507024: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e51900 of size 512 next 561\n",
            "2025-12-02 22:53:44.507027: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 749436e51b00 of size 3840 next 509\n",
            "2025-12-02 22:53:44.507030: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e52a00 of size 4096 next 510\n",
            "2025-12-02 22:53:44.507032: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e53a00 of size 4096 next 500\n",
            "2025-12-02 22:53:44.507035: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e54a00 of size 4096 next 507\n",
            "2025-12-02 22:53:44.507038: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e55a00 of size 4096 next 505\n",
            "2025-12-02 22:53:44.507040: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e56a00 of size 4096 next 498\n",
            "2025-12-02 22:53:44.507043: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e57a00 of size 14080 next 521\n",
            "2025-12-02 22:53:44.507046: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e5b100 of size 8192 next 522\n",
            "2025-12-02 22:53:44.507048: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e5d100 of size 8192 next 520\n",
            "2025-12-02 22:53:44.507051: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e5f100 of size 12288 next 516\n",
            "2025-12-02 22:53:44.507054: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e62100 of size 6144 next 519\n",
            "2025-12-02 22:53:44.507056: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e63900 of size 8192 next 525\n",
            "2025-12-02 22:53:44.507059: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 749436e65900 of size 22528 next 515\n",
            "2025-12-02 22:53:44.507062: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e6b100 of size 110592 next 524\n",
            "2025-12-02 22:53:44.507065: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e86100 of size 16384 next 319\n",
            "2025-12-02 22:53:44.507068: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e8a100 of size 16384 next 508\n",
            "2025-12-02 22:53:44.507071: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 749436e8e100 of size 22528 next 523\n",
            "2025-12-02 22:53:44.507073: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436e93900 of size 131072 next 294\n",
            "2025-12-02 22:53:44.507076: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436eb3900 of size 26368 next 479\n",
            "2025-12-02 22:53:44.507079: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436eba000 of size 26368 next 485\n",
            "2025-12-02 22:53:44.507081: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ec0700 of size 36864 next 506\n",
            "2025-12-02 22:53:44.507084: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ec9700 of size 59648 next 86\n",
            "2025-12-02 22:53:44.507087: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ed8000 of size 110592 next 278\n",
            "2025-12-02 22:53:44.507090: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ef3000 of size 3072 next 344\n",
            "2025-12-02 22:53:44.507092: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ef3c00 of size 3072 next 332\n",
            "2025-12-02 22:53:44.507095: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ef4800 of size 3328 next 346\n",
            "2025-12-02 22:53:44.507098: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ef5500 of size 3072 next 348\n",
            "2025-12-02 22:53:44.507100: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ef6100 of size 3072 next 347\n",
            "2025-12-02 22:53:44.507103: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ef6d00 of size 3072 next 349\n",
            "2025-12-02 22:53:44.507106: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ef7900 of size 3072 next 357\n",
            "2025-12-02 22:53:44.507109: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ef8500 of size 3072 next 355\n",
            "2025-12-02 22:53:44.507111: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ef9100 of size 3072 next 491\n",
            "2025-12-02 22:53:44.507114: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ef9d00 of size 4864 next 293\n",
            "2025-12-02 22:53:44.507116: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436efb000 of size 22528 next 277\n",
            "2025-12-02 22:53:44.507119: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436f00800 of size 65536 next 286\n",
            "2025-12-02 22:53:44.507122: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436f10800 of size 131072 next 287\n",
            "2025-12-02 22:53:44.507124: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436f30800 of size 262144 next 288\n",
            "2025-12-02 22:53:44.507127: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436f70800 of size 3072 next 368\n",
            "2025-12-02 22:53:44.507129: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436f71400 of size 3072 next 374\n",
            "2025-12-02 22:53:44.507132: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436f72000 of size 3072 next 372\n",
            "2025-12-02 22:53:44.507134: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436f72c00 of size 3072 next 373\n",
            "2025-12-02 22:53:44.507137: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436f73800 of size 3072 next 377\n",
            "2025-12-02 22:53:44.507139: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436f74400 of size 3072 next 380\n",
            "2025-12-02 22:53:44.507141: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436f75000 of size 3072 next 378\n",
            "2025-12-02 22:53:44.507144: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436f75c00 of size 4864 next 364\n",
            "2025-12-02 22:53:44.507146: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436f76f00 of size 26368 next 363\n",
            "2025-12-02 22:53:44.507149: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436f7d600 of size 26368 next 370\n",
            "2025-12-02 22:53:44.507151: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436f83d00 of size 36864 next 546\n",
            "2025-12-02 22:53:44.507153: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] Free  at 749436f8cd00 of size 146176 next 323\n",
            "2025-12-02 22:53:44.507156: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436fb0800 of size 131072 next 328\n",
            "2025-12-02 22:53:44.507158: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436fd0800 of size 26368 next 375\n",
            "2025-12-02 22:53:44.507161: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436fd6f00 of size 26368 next 381\n",
            "2025-12-02 22:53:44.507163: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436fdd600 of size 26368 next 386\n",
            "2025-12-02 22:53:44.507166: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436fe3d00 of size 26368 next 392\n",
            "2025-12-02 22:53:44.507168: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436fea400 of size 3072 next 402\n",
            "2025-12-02 22:53:44.507171: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436feb000 of size 3072 next 407\n",
            "2025-12-02 22:53:44.507174: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436febc00 of size 3072 next 405\n",
            "2025-12-02 22:53:44.507176: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436fec800 of size 3072 next 406\n",
            "2025-12-02 22:53:44.507179: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436fed400 of size 3072 next 411\n",
            "2025-12-02 22:53:44.507182: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436fee000 of size 3072 next 414\n",
            "2025-12-02 22:53:44.507185: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436feec00 of size 3072 next 412\n",
            "2025-12-02 22:53:44.507188: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436fef800 of size 4864 next 398\n",
            "2025-12-02 22:53:44.507190: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ff0b00 of size 26368 next 397\n",
            "2025-12-02 22:53:44.507193: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ff7200 of size 3072 next 483\n",
            "2025-12-02 22:53:44.507195: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ff7e00 of size 3072 next 489\n",
            "2025-12-02 22:53:44.507198: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ff8a00 of size 3072 next 487\n",
            "2025-12-02 22:53:44.507200: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ff9600 of size 3072 next 488\n",
            "2025-12-02 22:53:44.507203: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ffa200 of size 3072 next 492\n",
            "2025-12-02 22:53:44.507206: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ffae00 of size 4096 next 494\n",
            "2025-12-02 22:53:44.507208: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ffbe00 of size 4096 next 495\n",
            "2025-12-02 22:53:44.507211: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ffce00 of size 4096 next 496\n",
            "2025-12-02 22:53:44.507215: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ffde00 of size 256 next 499\n",
            "2025-12-02 22:53:44.507217: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ffdf00 of size 256 next 531\n",
            "2025-12-02 22:53:44.507220: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ffe000 of size 256 next 532\n",
            "2025-12-02 22:53:44.507224: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ffe100 of size 256 next 533\n",
            "2025-12-02 22:53:44.507226: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ffe200 of size 256 next 539\n",
            "2025-12-02 22:53:44.507228: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ffe300 of size 256 next 535\n",
            "2025-12-02 22:53:44.507231: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ffe400 of size 256 next 536\n",
            "2025-12-02 22:53:44.507234: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ffe500 of size 2304 next 493\n",
            "2025-12-02 22:53:44.507237: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749436ffee00 of size 4608 next 18446744073709551615\n",
            "2025-12-02 22:53:44.507239: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 8388608\n",
            "2025-12-02 22:53:44.507242: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749437000000 of size 2119936 next 139\n",
            "2025-12-02 22:53:44.507245: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 749437205900 of size 2981888 next 251\n",
            "2025-12-02 22:53:44.507248: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 7494374dd900 of size 3286784 next 18446744073709551615\n",
            "2025-12-02 22:53:44.507250: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1085] Next region of size 16777216\n",
            "2025-12-02 22:53:44.507253: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943aa00000 of size 2119936 next 104\n",
            "2025-12-02 22:53:44.507256: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943ac05900 of size 2119936 next 110\n",
            "2025-12-02 22:53:44.507258: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943ae0b200 of size 2119936 next 116\n",
            "2025-12-02 22:53:44.507261: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943b010b00 of size 2119936 next 121\n",
            "2025-12-02 22:53:44.507264: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943b216400 of size 2119936 next 127\n",
            "2025-12-02 22:53:44.507266: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943b41bd00 of size 2119936 next 132\n",
            "2025-12-02 22:53:44.507269: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1105] InUse at 74943b621600 of size 4057600 next 18446744073709551615\n",
            "2025-12-02 22:53:44.507272: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1110]      Summary of in-use Chunks by size: \n",
            "2025-12-02 22:53:44.507277: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 74 Chunks of size 256 totalling 18.5KiB\n",
            "2025-12-02 22:53:44.507280: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 25 Chunks of size 512 totalling 12.5KiB\n",
            "2025-12-02 22:53:44.507284: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 768 totalling 768B\n",
            "2025-12-02 22:53:44.507288: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 20 Chunks of size 1024 totalling 20.0KiB\n",
            "2025-12-02 22:53:44.507291: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 1280 totalling 2.5KiB\n",
            "2025-12-02 22:53:44.507294: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1536 totalling 1.5KiB\n",
            "2025-12-02 22:53:44.507298: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 3 Chunks of size 1792 totalling 5.2KiB\n",
            "2025-12-02 22:53:44.507300: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 2304 totalling 2.2KiB\n",
            "2025-12-02 22:53:44.507304: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 195 Chunks of size 3072 totalling 585.0KiB\n",
            "2025-12-02 22:53:44.507307: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 3 Chunks of size 3328 totalling 9.8KiB\n",
            "2025-12-02 22:53:44.507310: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 3584 totalling 7.0KiB\n",
            "2025-12-02 22:53:44.507314: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 17 Chunks of size 4096 totalling 68.0KiB\n",
            "2025-12-02 22:53:44.507317: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 5 Chunks of size 4608 totalling 22.5KiB\n",
            "2025-12-02 22:53:44.507320: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 20 Chunks of size 4864 totalling 95.0KiB\n",
            "2025-12-02 22:53:44.507323: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 5376 totalling 5.2KiB\n",
            "2025-12-02 22:53:44.507326: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 3 Chunks of size 5888 totalling 17.2KiB\n",
            "2025-12-02 22:53:44.507330: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 7 Chunks of size 6144 totalling 42.0KiB\n",
            "2025-12-02 22:53:44.507333: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 7168 totalling 7.0KiB\n",
            "2025-12-02 22:53:44.507336: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 7424 totalling 7.2KiB\n",
            "2025-12-02 22:53:44.507339: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 8 Chunks of size 8192 totalling 64.0KiB\n",
            "2025-12-02 22:53:44.507342: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 8960 totalling 8.8KiB\n",
            "2025-12-02 22:53:44.507347: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 3 Chunks of size 9216 totalling 27.0KiB\n",
            "2025-12-02 22:53:44.507350: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 12288 totalling 12.0KiB\n",
            "2025-12-02 22:53:44.507353: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 13312 totalling 13.0KiB\n",
            "2025-12-02 22:53:44.507357: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 14080 totalling 13.8KiB\n",
            "2025-12-02 22:53:44.507360: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 16384 totalling 32.0KiB\n",
            "2025-12-02 22:53:44.507363: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 22528 totalling 22.0KiB\n",
            "2025-12-02 22:53:44.507366: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 47 Chunks of size 26368 totalling 1.18MiB\n",
            "2025-12-02 22:53:44.507369: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 29696 totalling 29.0KiB\n",
            "2025-12-02 22:53:44.507372: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 4 Chunks of size 32768 totalling 128.0KiB\n",
            "2025-12-02 22:53:44.507376: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 34816 totalling 34.0KiB\n",
            "2025-12-02 22:53:44.507379: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 36096 totalling 35.2KiB\n",
            "2025-12-02 22:53:44.507382: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 3 Chunks of size 36864 totalling 108.0KiB\n",
            "2025-12-02 22:53:44.507385: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 40448 totalling 39.5KiB\n",
            "2025-12-02 22:53:44.507389: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 46080 totalling 45.0KiB\n",
            "2025-12-02 22:53:44.507392: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 50176 totalling 49.0KiB\n",
            "2025-12-02 22:53:44.507395: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 51968 totalling 50.8KiB\n",
            "2025-12-02 22:53:44.507399: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 59648 totalling 58.2KiB\n",
            "2025-12-02 22:53:44.507402: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 65536 totalling 64.0KiB\n",
            "2025-12-02 22:53:44.507406: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 67840 totalling 66.2KiB\n",
            "2025-12-02 22:53:44.507409: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 110592 totalling 216.0KiB\n",
            "2025-12-02 22:53:44.507412: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 118272 totalling 115.5KiB\n",
            "2025-12-02 22:53:44.507415: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 4 Chunks of size 131072 totalling 512.0KiB\n",
            "2025-12-02 22:53:44.507419: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 262144 totalling 512.0KiB\n",
            "2025-12-02 22:53:44.507422: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 3 Chunks of size 745472 totalling 2.13MiB\n",
            "2025-12-02 22:53:44.507425: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 1228800 totalling 1.17MiB\n",
            "2025-12-02 22:53:44.507428: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 47 Chunks of size 2119936 totalling 95.02MiB\n",
            "2025-12-02 22:53:44.507431: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 2456320 totalling 2.34MiB\n",
            "2025-12-02 22:53:44.507435: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 4 Chunks of size 2981888 totalling 11.38MiB\n",
            "2025-12-02 22:53:44.507438: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 3286784 totalling 3.13MiB\n",
            "2025-12-02 22:53:44.507441: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 3875328 totalling 3.70MiB\n",
            "2025-12-02 22:53:44.507445: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 4057600 totalling 7.74MiB\n",
            "2025-12-02 22:53:44.507448: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 6291456 totalling 12.00MiB\n",
            "2025-12-02 22:53:44.507451: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 8945664 totalling 8.53MiB\n",
            "2025-12-02 22:53:44.507455: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 12582912 totalling 12.00MiB\n",
            "2025-12-02 22:53:44.507458: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 14291200 totalling 13.63MiB\n",
            "2025-12-02 22:53:44.507462: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 16516096 totalling 31.50MiB\n",
            "2025-12-02 22:53:44.507465: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 2 Chunks of size 16777216 totalling 32.00MiB\n",
            "2025-12-02 22:53:44.507468: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 21856256 totalling 20.84MiB\n",
            "2025-12-02 22:53:44.507471: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 24214528 totalling 23.09MiB\n",
            "2025-12-02 22:53:44.507475: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 4 Chunks of size 32000000 totalling 122.07MiB\n",
            "2025-12-02 22:53:44.507478: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 3 Chunks of size 33032192 totalling 94.51MiB\n",
            "2025-12-02 22:53:44.507482: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 3 Chunks of size 64000000 totalling 183.11MiB\n",
            "2025-12-02 22:53:44.507485: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 104045568 totalling 99.23MiB\n",
            "2025-12-02 22:53:44.507488: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1113] 1 Chunks of size 240089088 totalling 228.97MiB\n",
            "2025-12-02 22:53:44.507492: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1117] Sum Total of in-use chunks: 1012.38MiB\n",
            "2025-12-02 22:53:44.507496: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1119] Total bytes in pool: 1062862848 memory_limit_: 1062862848 available bytes: 0 curr_region_allocation_bytes_: 1073741824\n",
            "2025-12-02 22:53:44.507503: I external/local_xla/xla/tsl/framework/bfc_allocator.cc:1124] Stats: \n",
            "Limit:                      1062862848\n",
            "InUse:                      1061554688\n",
            "MaxInUse:                   1061554688\n",
            "NumAllocs:                        2483\n",
            "MaxAllocSize:                240089088\n",
            "Reserved:                            0\n",
            "PeakReserved:                        0\n",
            "LargestFreeBlock:                    0\n",
            "\n",
            "2025-12-02 22:53:44.507520: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:512] ****************************************xxxxxxxxx***********************xx**************************\n",
            "2025-12-02 22:53:44.507547: W tensorflow/core/framework/op_kernel.cc:1842] RESOURCE_EXHAUSTED: failed to allocate memory\n",
            "2025-12-02 22:53:44.507573: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: RESOURCE_EXHAUSTED: failed to allocate memory\n"
          ]
        },
        {
          "ename": "ResourceExhaustedError",
          "evalue": "Exception encountered when calling BatchNormalization.call().\n\n\u001b[1m{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul] name: \u001b[0m\n\nArguments received by BatchNormalization.call():\n   inputs=tf.Tensor(shape=(16, 125, 125, 128), dtype=float16)\n   training=True\n   mask=None",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mResourceExhaustedError\u001b[39m                    Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 238\u001b[39m\n\u001b[32m    222\u001b[39m     train_generator = train_datagen.flow_from_directory(\n\u001b[32m    223\u001b[39m         Training_Path,\n\u001b[32m    224\u001b[39m         target_size=(\u001b[32m256\u001b[39m, \u001b[32m256\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m         classes=[\u001b[33m\"\u001b[39m\u001b[33mNon_Necrosis\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mNecrosis\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    228\u001b[39m     )\n\u001b[32m    230\u001b[39m     test_generator = test_datagen.flow_from_directory(\n\u001b[32m    231\u001b[39m         Testing_Path,\n\u001b[32m    232\u001b[39m         target_size=(\u001b[32m256\u001b[39m, \u001b[32m256\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m    235\u001b[39m         classes=[\u001b[33m\"\u001b[39m\u001b[33mNon_Necrosis\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mNecrosis\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    236\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m     \u001b[43mXceptionNet2048_original_Features_Optimized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBatch_Name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + \u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m60\u001b[39m)\n\u001b[32m    242\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m ALL BATCHES PROCESSED WITH TRAINED RELU FEATURES!\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 163\u001b[39m, in \u001b[36mXceptionNet2048_original_Features_Optimized\u001b[39m\u001b[34m(train_generator, test_generator, Batch)\u001b[39m\n\u001b[32m    154\u001b[39m val_gen_dense = val_aug.flow_from_directory(\n\u001b[32m    155\u001b[39m     test_generator.directory,\n\u001b[32m    156\u001b[39m     target_size=(\u001b[32m256\u001b[39m, \u001b[32m256\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m    159\u001b[39m     shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    160\u001b[39m )\n\u001b[32m    162\u001b[39m \u001b[38;5;66;03m# Load or build model\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m163\u001b[39m model = \u001b[43mget_feature_extraction_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_gen_dense\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_gen_dense\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;66;03m# Create output directory\u001b[39;00m\n\u001b[32m    166\u001b[39m current_dir = os.path.dirname(os.path.abspath(\u001b[33m'\u001b[39m\u001b[33m__file__\u001b[39m\u001b[33m'\u001b[39m))\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mget_feature_extraction_model\u001b[39m\u001b[34m(train_gen, val_gen)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;66;03m# Train Dense layer (only once)\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m train_gen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m val_gen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     model = \u001b[43mtrain_dense_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m trained_feature_model = Model(\n\u001b[32m     89\u001b[39m     inputs=model.input,\n\u001b[32m     90\u001b[39m     outputs=model.get_layer(\u001b[33m\"\u001b[39m\u001b[33mfeature_layer\u001b[39m\u001b[33m\"\u001b[39m).output\n\u001b[32m     91\u001b[39m )\n\u001b[32m     93\u001b[39m feature_save_path = os.path.join(\u001b[33m\"\u001b[39m\u001b[33msaved_models\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mXception_feature_extractor_original.h5\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 62\u001b[39m, in \u001b[36mtrain_dense_layer\u001b[39m\u001b[34m(model, train_generator, val_generator, epochs)\u001b[39m\n\u001b[32m     54\u001b[39m model.compile(\n\u001b[32m     55\u001b[39m     optimizer=tf.keras.optimizers.Adam(\u001b[32m1e-4\u001b[39m),\n\u001b[32m     56\u001b[39m     loss=\u001b[33m'\u001b[39m\u001b[33mcategorical_crossentropy\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     57\u001b[39m     metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     58\u001b[39m )\n\u001b[32m     60\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[TRAINING]  Training Dense(2048, ReLU) layer \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[TRAINING]  Dense layer training finished!\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/pathologyStudentsAug25/env/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/pathologyStudentsAug25/env/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "\u001b[31mResourceExhaustedError\u001b[39m: Exception encountered when calling BatchNormalization.call().\n\n\u001b[1m{{function_node __wrapped__Mul_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:Mul] name: \u001b[0m\n\nArguments received by BatchNormalization.call():\n   inputs=tf.Tensor(shape=(16, 125, 125, 128), dtype=float16)\n   training=True\n   mask=None"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
        "import gc\n",
        "\n",
        "# =========================================\n",
        "#  GPU MEMORY MANAGEMENT\n",
        "# =========================================\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')   # reduce memory by ~40%\n",
        "\n",
        "# =========================================\n",
        "#  GLOBAL MODEL CACHE\n",
        "# =========================================\n",
        "_cached_model = None\n",
        "\n",
        "\n",
        "# =============================================================\n",
        "# 1 BUILD FEATURE EXTRACTOR (WITH TRAINABLE RELU LAYER)\n",
        "# =============================================================\n",
        "def build_feature_extractor_with_relu():\n",
        "    base_model = Xception(\n",
        "        weights='imagenet',\n",
        "        include_top=False,\n",
        "        input_shape=(256, 256, 3)\n",
        "    )\n",
        "\n",
        "    # Freeze the Xception base model\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    # Add trainable Dense(2048, relu)\n",
        "    x = GlobalAveragePooling2D()(base_model.output)\n",
        "    x = Dense(2048, activation='relu', dtype='float32', name=\"feature_layer\",trainable=True)(x)\n",
        "\n",
        "    output = Dense(2, activation='softmax', dtype='float32')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "    print(\"[INFO] Model created  Base frozen + Trainable Dense(2048, ReLU)\")\n",
        "    return model\n",
        "\n",
        "\n",
        "# =============================================================\n",
        "# 2 TRAIN ONLY THE DENSE(2048, RELU) LAYER\n",
        "# =============================================================\n",
        "def train_dense_layer(model, train_generator, val_generator, epochs=3):\n",
        "    \"\"\"Train the trainable Dense layer to learn better features.\"\"\"\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(\"\\n[TRAINING]  Training Dense(2048, ReLU) layer \")\n",
        "\n",
        "    model.fit(\n",
        "        train_generator,\n",
        "        validation_data=val_generator,\n",
        "        epochs=epochs\n",
        "    )\n",
        "\n",
        "    print(\"[TRAINING]  Dense layer training finished!\\n\")\n",
        "    return model\n",
        "\n",
        "\n",
        "# =============================================================\n",
        "# 3 GET CACHED MODEL OR TRAIN NEW ONE\n",
        "# =============================================================\n",
        "def get_feature_extraction_model(train_gen=None, val_gen=None):\n",
        "    global _cached_model\n",
        "\n",
        "    if _cached_model is None:\n",
        "        print(\"[INFO] Building model for first time\")\n",
        "\n",
        "        # Build model\n",
        "        model = build_feature_extractor_with_relu()\n",
        "\n",
        "        # Train Dense layer (only once)\n",
        "        if train_gen is not None and val_gen is not None:\n",
        "            model = train_dense_layer(model, train_gen, val_gen, epochs=3)\n",
        "\n",
        "        trained_feature_model = Model(\n",
        "            inputs=model.input,\n",
        "            outputs=model.get_layer(\"feature_layer\").output\n",
        "        )\n",
        "\n",
        "        feature_save_path = os.path.join(\"saved_models\", \"Xception_feature_extractor_original.h5\")\n",
        "        trained_feature_model.save(feature_save_path)\n",
        "\n",
        "        _cached_model = trained_feature_model\n",
        "        print(\"[INFO]  Feature extraction model cached\")\n",
        "\n",
        "    return _cached_model\n",
        "\n",
        "\n",
        "# =============================================================\n",
        "# 4 CHUNK-BASED FEATURE EXTRACTION\n",
        "# =============================================================\n",
        "def extract_features_in_chunks(generator, model, chunk_size=32):\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "    all_filenames = []\n",
        "\n",
        "    total_samples = len(generator.filenames)\n",
        "    steps = int(np.ceil(total_samples / generator.batch_size))\n",
        "\n",
        "    print(f\"[INFO] Extracting {total_samples} images in {steps} steps\")\n",
        "\n",
        "    for step in range(steps):\n",
        "        try:\n",
        "            batch_x, batch_y = next(generator)\n",
        "            batch_features = model.predict(batch_x, verbose=0)\n",
        "\n",
        "            all_features.append(batch_features)\n",
        "            all_labels.extend(np.argmax(batch_y, axis=1))\n",
        "            all_filenames.extend(generator.filenames[step*generator.batch_size:(step+1)*generator.batch_size])\n",
        "\n",
        "            if (step + 1) % 10 == 0:\n",
        "                print(f\"  [Progress] {step + 1}/{steps}\")\n",
        "                gc.collect()\n",
        "\n",
        "        except StopIteration:\n",
        "            break\n",
        "\n",
        "    features = np.vstack(all_features)\n",
        "    print(f\"[INFO]  Final features shape: {features.shape}\")\n",
        "    return features, np.array(all_labels), all_filenames[:len(all_labels)]\n",
        "\n",
        "\n",
        "# =============================================================\n",
        "# 5 MAIN EXTRACTION FUNCTION\n",
        "# =============================================================\n",
        "def XceptionNet2048_original_Features_Optimized(train_generator, test_generator, Batch):\n",
        "\n",
        "    # TRAINING DIRECTORIES FOR DENSE LAYER\n",
        "    # (You MUST create separate augmentation generators)\n",
        "    train_aug = ImageDataGenerator(rescale=1/255, rotation_range=20, horizontal_flip=True)\n",
        "    val_aug = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "    train_gen_dense = train_aug.flow_from_directory(\n",
        "        train_generator.directory,\n",
        "        target_size=(256, 256),\n",
        "        batch_size=16,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    val_gen_dense = val_aug.flow_from_directory(\n",
        "        test_generator.directory,\n",
        "        target_size=(256, 256),\n",
        "        batch_size=16,\n",
        "        class_mode='categorical',\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    # Load or build model\n",
        "    model = get_feature_extraction_model(train_gen_dense, val_gen_dense)\n",
        "\n",
        "    # Create output directory\n",
        "    current_dir = os.path.dirname(os.path.abspath('__file__'))\n",
        "    parent_dir = os.path.dirname(current_dir)\n",
        "    root_dir = os.path.dirname(parent_dir)\n",
        "    save_drive_dir = os.path.join(root_dir, 'pathologyStudentsAug25', 'Results', 'XceptionNet2048+SVM')\n",
        "    batch_output_dir = os.path.join(save_drive_dir, Batch)\n",
        "    os.makedirs(batch_output_dir, exist_ok=True)\n",
        "\n",
        "    # EXTRACT FEATURES\n",
        "    print(f\"\\n[STEP 1] Extracting training features for {Batch}\")\n",
        "    f_train, y_train, n_train = extract_features_in_chunks(train_generator, model)\n",
        "\n",
        "    print(f\"\\n[STEP 2] Extracting test features for {Batch}\")\n",
        "    f_test, y_test, n_test = extract_features_in_chunks(test_generator, model)\n",
        "\n",
        "    # SAVE FEATURES\n",
        "    cols = [f\"feature_{i}\" for i in range(f_train.shape[1])]\n",
        "\n",
        "    df_train = pd.DataFrame(f_train, columns=cols)\n",
        "    df_train[\"label\"] = y_train\n",
        "    df_train[\"Image_Name\"] = n_train\n",
        "    df_train.to_csv(os.path.join(batch_output_dir, \"XceptionNet2048_Training.csv\"), index=False)\n",
        "\n",
        "    df_test = pd.DataFrame(f_test, columns=cols)\n",
        "    df_test[\"label\"] = y_test\n",
        "    df_test[\"Image_Name\"] = n_test\n",
        "    df_test.to_csv(os.path.join(batch_output_dir, \"XceptionNet2048_Testing.csv\"), index=False)\n",
        "\n",
        "    print(f\"[DONE] Features saved for {Batch}\\n\")\n",
        "\n",
        "\n",
        "# =============================================================\n",
        "# 6 PROCESS ALL BATCHES\n",
        "# =============================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" STARTING OPTIMIZED FEATURE EXTRACTION (ReLU + TRAINED)\")\n",
        "print(\"=\"*60 + \"\\n\")\n",
        "\n",
        "for x in range(16, 20):\n",
        "\n",
        "    batch_size = 32\n",
        "    Batch_Name = f\"Batch_{x}\"\n",
        "\n",
        "    current_dir = os.path.dirname(os.path.abspath('__file__'))\n",
        "    parent_dir = os.path.dirname(current_dir)\n",
        "    root_dir = os.path.dirname(parent_dir)\n",
        "\n",
        "    Training_Path = os.path.join(root_dir, \"pathologyStudentsAug25\", \"original\", Batch_Name, \"Training\")\n",
        "    Testing_Path = os.path.join(root_dir, \"pathologyStudentsAug25\", \"original\", Batch_Name, \"Testing\")\n",
        "\n",
        "    if not os.path.exists(Training_Path):\n",
        "        print(f\"[SKIP] Missing path: {Training_Path}\")\n",
        "        continue\n",
        "\n",
        "    train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "    test_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        Training_Path,\n",
        "        target_size=(256, 256),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        classes=[\"Non_Necrosis\", \"Necrosis\"]\n",
        "    )\n",
        "\n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        Testing_Path,\n",
        "        target_size=(256, 256),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        classes=[\"Non_Necrosis\", \"Necrosis\"]\n",
        "    )\n",
        "\n",
        "    XceptionNet2048_original_Features_Optimized(train_generator, test_generator, Batch_Name)\n",
        "\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" ALL BATCHES PROCESSED WITH TRAINED RELU FEATURES!\")\n",
        "print(\"=\"*60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "============================================================\n",
            "STARTING OPTIMIZED BATCH PROCESSING - FULL DATA (100%)\n",
            "============================================================\n",
            "Found 6342 images belonging to 2 classes.\n",
            "Found 33 images belonging to 2 classes.\n",
            "\n",
            "============================================================\n",
            "[BATCH] Processing Batch_1\n",
            "============================================================\n",
            "[INFO]  Feature extraction model loaded (cached)\n",
            "\n",
            "[STEP 1/2] Extracting training features...\n",
            "[INFO] Extracting features from 6342 images in 793 steps...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-17 19:28:03.261278: E tensorflow/core/util/util.cc:131] oneDNN supports DT_HALF only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n",
            "2025-11-17 19:28:03.301321: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91300\n",
            "2025-11-17 19:28:10.984220: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 88.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  [Progress] 10/793 batches processed...\n",
            "  [Progress] 20/793 batches processed...\n",
            "  [Progress] 30/793 batches processed...\n",
            "  [Progress] 40/793 batches processed...\n",
            "  [Progress] 50/793 batches processed...\n",
            "  [Progress] 60/793 batches processed...\n",
            "  [Progress] 70/793 batches processed...\n",
            "  [Progress] 80/793 batches processed...\n",
            "  [Progress] 90/793 batches processed...\n",
            "  [Progress] 100/793 batches processed...\n",
            "  [Progress] 110/793 batches processed...\n",
            "  [Progress] 120/793 batches processed...\n",
            "  [Progress] 130/793 batches processed...\n",
            "  [Progress] 140/793 batches processed...\n",
            "  [Progress] 150/793 batches processed...\n",
            "  [Progress] 160/793 batches processed...\n",
            "  [Progress] 170/793 batches processed...\n",
            "  [Progress] 180/793 batches processed...\n",
            "  [Progress] 190/793 batches processed...\n",
            "  [Progress] 200/793 batches processed...\n",
            "  [Progress] 210/793 batches processed...\n",
            "  [Progress] 220/793 batches processed...\n",
            "  [Progress] 230/793 batches processed...\n",
            "  [Progress] 240/793 batches processed...\n",
            "  [Progress] 250/793 batches processed...\n",
            "  [Progress] 260/793 batches processed...\n",
            "  [Progress] 270/793 batches processed...\n",
            "  [Progress] 280/793 batches processed...\n",
            "  [Progress] 290/793 batches processed...\n",
            "  [Progress] 300/793 batches processed...\n",
            "  [Progress] 310/793 batches processed...\n",
            "  [Progress] 320/793 batches processed...\n",
            "  [Progress] 330/793 batches processed...\n",
            "  [Progress] 340/793 batches processed...\n",
            "  [Progress] 350/793 batches processed...\n",
            "  [Progress] 360/793 batches processed...\n",
            "  [Progress] 370/793 batches processed...\n",
            "  [Progress] 380/793 batches processed...\n",
            "  [Progress] 390/793 batches processed...\n",
            "  [Progress] 400/793 batches processed...\n",
            "  [Progress] 410/793 batches processed...\n",
            "  [Progress] 420/793 batches processed...\n",
            "  [Progress] 430/793 batches processed...\n",
            "  [Progress] 440/793 batches processed...\n",
            "  [Progress] 450/793 batches processed...\n",
            "  [Progress] 460/793 batches processed...\n",
            "  [Progress] 470/793 batches processed...\n",
            "  [Progress] 480/793 batches processed...\n",
            "  [Progress] 490/793 batches processed...\n",
            "  [Progress] 500/793 batches processed...\n",
            "  [Progress] 510/793 batches processed...\n",
            "  [Progress] 520/793 batches processed...\n",
            "  [Progress] 530/793 batches processed...\n",
            "  [Progress] 540/793 batches processed...\n",
            "  [Progress] 550/793 batches processed...\n",
            "  [Progress] 560/793 batches processed...\n",
            "  [Progress] 570/793 batches processed...\n",
            "  [Progress] 580/793 batches processed...\n",
            "  [Progress] 590/793 batches processed...\n",
            "  [Progress] 600/793 batches processed...\n",
            "  [Progress] 610/793 batches processed...\n",
            "  [Progress] 620/793 batches processed...\n",
            "  [Progress] 630/793 batches processed...\n",
            "  [Progress] 640/793 batches processed...\n",
            "  [Progress] 650/793 batches processed...\n",
            "  [Progress] 660/793 batches processed...\n",
            "  [Progress] 670/793 batches processed...\n",
            "  [Progress] 680/793 batches processed...\n",
            "  [Progress] 690/793 batches processed...\n",
            "  [Progress] 700/793 batches processed...\n",
            "  [Progress] 710/793 batches processed...\n",
            "  [Progress] 720/793 batches processed...\n",
            "  [Progress] 730/793 batches processed...\n",
            "  [Progress] 740/793 batches processed...\n",
            "  [Progress] 750/793 batches processed...\n",
            "  [Progress] 760/793 batches processed...\n",
            "  [Progress] 770/793 batches processed...\n",
            "  [Progress] 780/793 batches processed...\n",
            "  [Progress] 790/793 batches processed...\n",
            "[INFO]  Total features extracted: (6342, 2048)\n",
            "\n",
            "[STEP 1/2] Extracting testing features...\n",
            "[INFO] Extracting features from 33 images in 5 steps...\n",
            "[INFO]  Total features extracted: (33, 2048)\n",
            "[STEP 2/2]  Training features saved: 6342 samples\n",
            "[STEP 2/2]  Testing features saved: 33 samples\n",
            "\n",
            "[INFO]  Batch_1 completed successfully!\n",
            "\n",
            "Found 5741 images belonging to 2 classes.\n",
            "Found 183 images belonging to 2 classes.\n",
            "\n",
            "============================================================\n",
            "[BATCH] Processing Batch_2\n",
            "============================================================\n",
            "\n",
            "[STEP 1/2] Extracting training features...\n",
            "[INFO] Extracting features from 5741 images in 718 steps...\n",
            "  [Progress] 10/718 batches processed...\n",
            "  [Progress] 20/718 batches processed...\n",
            "  [Progress] 30/718 batches processed...\n",
            "  [Progress] 40/718 batches processed...\n",
            "  [Progress] 50/718 batches processed...\n",
            "  [Progress] 60/718 batches processed...\n",
            "  [Progress] 70/718 batches processed...\n",
            "  [Progress] 80/718 batches processed...\n",
            "  [Progress] 90/718 batches processed...\n",
            "  [Progress] 100/718 batches processed...\n",
            "  [Progress] 110/718 batches processed...\n",
            "  [Progress] 120/718 batches processed...\n",
            "  [Progress] 130/718 batches processed...\n",
            "  [Progress] 140/718 batches processed...\n",
            "  [Progress] 150/718 batches processed...\n",
            "  [Progress] 160/718 batches processed...\n",
            "  [Progress] 170/718 batches processed...\n",
            "  [Progress] 180/718 batches processed...\n",
            "  [Progress] 190/718 batches processed...\n",
            "  [Progress] 200/718 batches processed...\n",
            "  [Progress] 210/718 batches processed...\n",
            "  [Progress] 220/718 batches processed...\n",
            "  [Progress] 230/718 batches processed...\n",
            "  [Progress] 240/718 batches processed...\n",
            "  [Progress] 250/718 batches processed...\n",
            "  [Progress] 260/718 batches processed...\n",
            "  [Progress] 270/718 batches processed...\n",
            "  [Progress] 280/718 batches processed...\n",
            "  [Progress] 290/718 batches processed...\n",
            "  [Progress] 300/718 batches processed...\n",
            "  [Progress] 310/718 batches processed...\n",
            "  [Progress] 320/718 batches processed...\n",
            "  [Progress] 330/718 batches processed...\n",
            "  [Progress] 340/718 batches processed...\n",
            "  [Progress] 350/718 batches processed...\n",
            "  [Progress] 360/718 batches processed...\n",
            "  [Progress] 370/718 batches processed...\n",
            "  [Progress] 380/718 batches processed...\n",
            "  [Progress] 390/718 batches processed...\n",
            "  [Progress] 400/718 batches processed...\n",
            "  [Progress] 410/718 batches processed...\n",
            "  [Progress] 420/718 batches processed...\n",
            "  [Progress] 430/718 batches processed...\n",
            "  [Progress] 440/718 batches processed...\n",
            "  [Progress] 450/718 batches processed...\n",
            "  [Progress] 460/718 batches processed...\n",
            "  [Progress] 470/718 batches processed...\n",
            "  [Progress] 480/718 batches processed...\n",
            "  [Progress] 490/718 batches processed...\n",
            "  [Progress] 500/718 batches processed...\n",
            "  [Progress] 510/718 batches processed...\n",
            "  [Progress] 520/718 batches processed...\n",
            "  [Progress] 530/718 batches processed...\n",
            "  [Progress] 540/718 batches processed...\n",
            "  [Progress] 550/718 batches processed...\n",
            "  [Progress] 560/718 batches processed...\n",
            "  [Progress] 570/718 batches processed...\n",
            "  [Progress] 580/718 batches processed...\n",
            "  [Progress] 590/718 batches processed...\n",
            "  [Progress] 600/718 batches processed...\n",
            "  [Progress] 610/718 batches processed...\n",
            "  [Progress] 620/718 batches processed...\n",
            "  [Progress] 630/718 batches processed...\n",
            "  [Progress] 640/718 batches processed...\n",
            "  [Progress] 650/718 batches processed...\n",
            "  [Progress] 660/718 batches processed...\n",
            "  [Progress] 670/718 batches processed...\n",
            "  [Progress] 680/718 batches processed...\n",
            "  [Progress] 690/718 batches processed...\n",
            "  [Progress] 700/718 batches processed...\n",
            "  [Progress] 710/718 batches processed...\n",
            "[INFO]  Total features extracted: (5741, 2048)\n",
            "\n",
            "[STEP 1/2] Extracting testing features...\n",
            "[INFO] Extracting features from 183 images in 23 steps...\n",
            "  [Progress] 10/23 batches processed...\n",
            "  [Progress] 20/23 batches processed...\n",
            "[INFO]  Total features extracted: (183, 2048)\n",
            "[STEP 2/2]  Training features saved: 5741 samples\n",
            "[STEP 2/2]  Testing features saved: 183 samples\n",
            "\n",
            "[INFO]  Batch_2 completed successfully!\n",
            "\n",
            "Found 6412 images belonging to 2 classes.\n",
            "Found 15 images belonging to 2 classes.\n",
            "\n",
            "============================================================\n",
            "[BATCH] Processing Batch_3\n",
            "============================================================\n",
            "\n",
            "[STEP 1/2] Extracting training features...\n",
            "[INFO] Extracting features from 6412 images in 802 steps...\n",
            "  [Progress] 10/802 batches processed...\n",
            "  [Progress] 20/802 batches processed...\n",
            "  [Progress] 30/802 batches processed...\n",
            "  [Progress] 40/802 batches processed...\n",
            "  [Progress] 50/802 batches processed...\n",
            "  [Progress] 60/802 batches processed...\n",
            "  [Progress] 70/802 batches processed...\n",
            "  [Progress] 80/802 batches processed...\n",
            "  [Progress] 90/802 batches processed...\n",
            "  [Progress] 100/802 batches processed...\n",
            "  [Progress] 110/802 batches processed...\n",
            "  [Progress] 120/802 batches processed...\n",
            "  [Progress] 130/802 batches processed...\n",
            "  [Progress] 140/802 batches processed...\n",
            "  [Progress] 150/802 batches processed...\n",
            "  [Progress] 160/802 batches processed...\n",
            "  [Progress] 170/802 batches processed...\n",
            "  [Progress] 180/802 batches processed...\n",
            "  [Progress] 190/802 batches processed...\n",
            "  [Progress] 200/802 batches processed...\n",
            "  [Progress] 210/802 batches processed...\n",
            "  [Progress] 220/802 batches processed...\n",
            "  [Progress] 230/802 batches processed...\n",
            "  [Progress] 240/802 batches processed...\n",
            "  [Progress] 250/802 batches processed...\n",
            "  [Progress] 260/802 batches processed...\n",
            "  [Progress] 270/802 batches processed...\n",
            "  [Progress] 280/802 batches processed...\n",
            "  [Progress] 290/802 batches processed...\n",
            "  [Progress] 300/802 batches processed...\n",
            "  [Progress] 310/802 batches processed...\n",
            "  [Progress] 320/802 batches processed...\n",
            "  [Progress] 330/802 batches processed...\n",
            "  [Progress] 340/802 batches processed...\n",
            "  [Progress] 350/802 batches processed...\n",
            "  [Progress] 360/802 batches processed...\n",
            "  [Progress] 370/802 batches processed...\n",
            "  [Progress] 380/802 batches processed...\n",
            "  [Progress] 390/802 batches processed...\n",
            "  [Progress] 400/802 batches processed...\n",
            "  [Progress] 410/802 batches processed...\n",
            "  [Progress] 420/802 batches processed...\n",
            "  [Progress] 430/802 batches processed...\n",
            "  [Progress] 440/802 batches processed...\n",
            "  [Progress] 450/802 batches processed...\n",
            "  [Progress] 460/802 batches processed...\n",
            "  [Progress] 470/802 batches processed...\n",
            "  [Progress] 480/802 batches processed...\n",
            "  [Progress] 490/802 batches processed...\n",
            "  [Progress] 500/802 batches processed...\n",
            "  [Progress] 510/802 batches processed...\n",
            "  [Progress] 520/802 batches processed...\n",
            "  [Progress] 530/802 batches processed...\n",
            "  [Progress] 540/802 batches processed...\n",
            "  [Progress] 550/802 batches processed...\n",
            "  [Progress] 560/802 batches processed...\n",
            "  [Progress] 570/802 batches processed...\n",
            "  [Progress] 580/802 batches processed...\n",
            "  [Progress] 590/802 batches processed...\n",
            "  [Progress] 600/802 batches processed...\n",
            "  [Progress] 610/802 batches processed...\n",
            "  [Progress] 620/802 batches processed...\n",
            "  [Progress] 630/802 batches processed...\n",
            "  [Progress] 640/802 batches processed...\n",
            "  [Progress] 650/802 batches processed...\n",
            "  [Progress] 660/802 batches processed...\n",
            "  [Progress] 670/802 batches processed...\n",
            "  [Progress] 680/802 batches processed...\n",
            "  [Progress] 690/802 batches processed...\n",
            "  [Progress] 700/802 batches processed...\n",
            "  [Progress] 710/802 batches processed...\n",
            "  [Progress] 720/802 batches processed...\n",
            "  [Progress] 730/802 batches processed...\n",
            "  [Progress] 740/802 batches processed...\n",
            "  [Progress] 750/802 batches processed...\n",
            "  [Progress] 760/802 batches processed...\n",
            "  [Progress] 770/802 batches processed...\n",
            "  [Progress] 780/802 batches processed...\n",
            "  [Progress] 790/802 batches processed...\n",
            "  [Progress] 800/802 batches processed...\n",
            "[INFO]  Total features extracted: (6412, 2048)\n",
            "\n",
            "[STEP 1/2] Extracting testing features...\n",
            "[INFO] Extracting features from 15 images in 2 steps...\n",
            "[INFO]  Total features extracted: (15, 2048)\n",
            "[STEP 2/2]  Training features saved: 6412 samples\n",
            "[STEP 2/2]  Testing features saved: 15 samples\n",
            "\n",
            "[INFO]  Batch_3 completed successfully!\n",
            "\n",
            "Found 6388 images belonging to 2 classes.\n",
            "Found 564 images belonging to 2 classes.\n",
            "\n",
            "============================================================\n",
            "[BATCH] Processing Batch_4\n",
            "============================================================\n",
            "\n",
            "[STEP 1/2] Extracting training features...\n",
            "[INFO] Extracting features from 6388 images in 799 steps...\n",
            "  [Progress] 10/799 batches processed...\n",
            "  [Progress] 20/799 batches processed...\n",
            "  [Progress] 30/799 batches processed...\n",
            "  [Progress] 40/799 batches processed...\n",
            "  [Progress] 50/799 batches processed...\n",
            "  [Progress] 60/799 batches processed...\n",
            "  [Progress] 70/799 batches processed...\n",
            "  [Progress] 80/799 batches processed...\n",
            "  [Progress] 90/799 batches processed...\n",
            "  [Progress] 100/799 batches processed...\n",
            "  [Progress] 110/799 batches processed...\n",
            "  [Progress] 120/799 batches processed...\n",
            "  [Progress] 130/799 batches processed...\n",
            "  [Progress] 140/799 batches processed...\n",
            "  [Progress] 150/799 batches processed...\n",
            "  [Progress] 160/799 batches processed...\n",
            "  [Progress] 170/799 batches processed...\n",
            "  [Progress] 180/799 batches processed...\n",
            "  [Progress] 190/799 batches processed...\n",
            "  [Progress] 200/799 batches processed...\n",
            "  [Progress] 210/799 batches processed...\n",
            "  [Progress] 220/799 batches processed...\n",
            "  [Progress] 230/799 batches processed...\n",
            "  [Progress] 240/799 batches processed...\n",
            "  [Progress] 250/799 batches processed...\n",
            "  [Progress] 260/799 batches processed...\n",
            "  [Progress] 270/799 batches processed...\n",
            "  [Progress] 280/799 batches processed...\n",
            "  [Progress] 290/799 batches processed...\n",
            "  [Progress] 300/799 batches processed...\n",
            "  [Progress] 310/799 batches processed...\n",
            "  [Progress] 320/799 batches processed...\n",
            "  [Progress] 330/799 batches processed...\n",
            "  [Progress] 340/799 batches processed...\n",
            "  [Progress] 350/799 batches processed...\n",
            "  [Progress] 360/799 batches processed...\n",
            "  [Progress] 370/799 batches processed...\n",
            "  [Progress] 380/799 batches processed...\n",
            "  [Progress] 390/799 batches processed...\n",
            "  [Progress] 400/799 batches processed...\n",
            "  [Progress] 410/799 batches processed...\n",
            "  [Progress] 420/799 batches processed...\n",
            "  [Progress] 430/799 batches processed...\n",
            "  [Progress] 440/799 batches processed...\n",
            "  [Progress] 450/799 batches processed...\n",
            "  [Progress] 460/799 batches processed...\n",
            "  [Progress] 470/799 batches processed...\n",
            "  [Progress] 480/799 batches processed...\n",
            "  [Progress] 490/799 batches processed...\n",
            "  [Progress] 500/799 batches processed...\n",
            "  [Progress] 510/799 batches processed...\n",
            "  [Progress] 520/799 batches processed...\n",
            "  [Progress] 530/799 batches processed...\n",
            "  [Progress] 540/799 batches processed...\n",
            "  [Progress] 550/799 batches processed...\n",
            "  [Progress] 560/799 batches processed...\n",
            "  [Progress] 570/799 batches processed...\n",
            "  [Progress] 580/799 batches processed...\n",
            "  [Progress] 590/799 batches processed...\n",
            "  [Progress] 600/799 batches processed...\n",
            "  [Progress] 610/799 batches processed...\n",
            "  [Progress] 620/799 batches processed...\n",
            "  [Progress] 630/799 batches processed...\n",
            "  [Progress] 640/799 batches processed...\n",
            "  [Progress] 650/799 batches processed...\n",
            "  [Progress] 660/799 batches processed...\n",
            "  [Progress] 670/799 batches processed...\n",
            "  [Progress] 680/799 batches processed...\n",
            "  [Progress] 690/799 batches processed...\n",
            "  [Progress] 700/799 batches processed...\n",
            "  [Progress] 710/799 batches processed...\n",
            "  [Progress] 720/799 batches processed...\n",
            "  [Progress] 730/799 batches processed...\n",
            "  [Progress] 740/799 batches processed...\n",
            "  [Progress] 750/799 batches processed...\n",
            "  [Progress] 760/799 batches processed...\n",
            "  [Progress] 770/799 batches processed...\n",
            "  [Progress] 780/799 batches processed...\n",
            "  [Progress] 790/799 batches processed...\n",
            "[INFO]  Total features extracted: (6388, 2048)\n",
            "\n",
            "[STEP 1/2] Extracting testing features...\n",
            "[INFO] Extracting features from 564 images in 71 steps...\n",
            "  [Progress] 10/71 batches processed...\n",
            "  [Progress] 20/71 batches processed...\n",
            "  [Progress] 30/71 batches processed...\n",
            "  [Progress] 40/71 batches processed...\n",
            "  [Progress] 50/71 batches processed...\n",
            "  [Progress] 60/71 batches processed...\n",
            "  [Progress] 70/71 batches processed...\n",
            "[INFO]  Total features extracted: (564, 2048)\n",
            "[STEP 2/2]  Training features saved: 6388 samples\n",
            "[STEP 2/2]  Testing features saved: 564 samples\n",
            "\n",
            "[INFO]  Batch_4 completed successfully!\n",
            "\n",
            "Found 6475 images belonging to 2 classes.\n",
            "Found 1215 images belonging to 2 classes.\n",
            "\n",
            "============================================================\n",
            "[BATCH] Processing Batch_5\n",
            "============================================================\n",
            "\n",
            "[STEP 1/2] Extracting training features...\n",
            "[INFO] Extracting features from 6475 images in 810 steps...\n",
            "  [Progress] 10/810 batches processed...\n",
            "  [Progress] 20/810 batches processed...\n",
            "  [Progress] 30/810 batches processed...\n",
            "  [Progress] 40/810 batches processed...\n",
            "  [Progress] 50/810 batches processed...\n",
            "  [Progress] 60/810 batches processed...\n",
            "  [Progress] 70/810 batches processed...\n",
            "  [Progress] 80/810 batches processed...\n",
            "  [Progress] 90/810 batches processed...\n",
            "  [Progress] 100/810 batches processed...\n",
            "  [Progress] 110/810 batches processed...\n",
            "  [Progress] 120/810 batches processed...\n",
            "  [Progress] 130/810 batches processed...\n",
            "  [Progress] 140/810 batches processed...\n",
            "  [Progress] 150/810 batches processed...\n",
            "  [Progress] 160/810 batches processed...\n",
            "  [Progress] 170/810 batches processed...\n",
            "  [Progress] 180/810 batches processed...\n",
            "  [Progress] 190/810 batches processed...\n",
            "  [Progress] 200/810 batches processed...\n",
            "  [Progress] 210/810 batches processed...\n",
            "  [Progress] 220/810 batches processed...\n",
            "  [Progress] 230/810 batches processed...\n",
            "  [Progress] 240/810 batches processed...\n",
            "  [Progress] 250/810 batches processed...\n",
            "  [Progress] 260/810 batches processed...\n",
            "  [Progress] 270/810 batches processed...\n",
            "  [Progress] 280/810 batches processed...\n",
            "  [Progress] 290/810 batches processed...\n",
            "  [Progress] 300/810 batches processed...\n",
            "  [Progress] 310/810 batches processed...\n",
            "  [Progress] 320/810 batches processed...\n",
            "  [Progress] 330/810 batches processed...\n",
            "  [Progress] 340/810 batches processed...\n",
            "  [Progress] 350/810 batches processed...\n",
            "  [Progress] 360/810 batches processed...\n",
            "  [Progress] 370/810 batches processed...\n",
            "  [Progress] 380/810 batches processed...\n",
            "  [Progress] 390/810 batches processed...\n",
            "  [Progress] 400/810 batches processed...\n",
            "  [Progress] 410/810 batches processed...\n",
            "  [Progress] 420/810 batches processed...\n",
            "  [Progress] 430/810 batches processed...\n",
            "  [Progress] 440/810 batches processed...\n",
            "  [Progress] 450/810 batches processed...\n",
            "  [Progress] 460/810 batches processed...\n",
            "  [Progress] 470/810 batches processed...\n",
            "  [Progress] 480/810 batches processed...\n",
            "  [Progress] 490/810 batches processed...\n",
            "  [Progress] 500/810 batches processed...\n",
            "  [Progress] 510/810 batches processed...\n",
            "  [Progress] 520/810 batches processed...\n",
            "  [Progress] 530/810 batches processed...\n",
            "  [Progress] 540/810 batches processed...\n",
            "  [Progress] 550/810 batches processed...\n",
            "  [Progress] 560/810 batches processed...\n",
            "  [Progress] 570/810 batches processed...\n",
            "  [Progress] 580/810 batches processed...\n",
            "  [Progress] 590/810 batches processed...\n",
            "  [Progress] 600/810 batches processed...\n",
            "  [Progress] 610/810 batches processed...\n",
            "  [Progress] 620/810 batches processed...\n",
            "  [Progress] 630/810 batches processed...\n",
            "  [Progress] 640/810 batches processed...\n",
            "  [Progress] 650/810 batches processed...\n",
            "  [Progress] 660/810 batches processed...\n",
            "  [Progress] 670/810 batches processed...\n",
            "  [Progress] 680/810 batches processed...\n",
            "  [Progress] 690/810 batches processed...\n",
            "  [Progress] 700/810 batches processed...\n",
            "  [Progress] 710/810 batches processed...\n",
            "  [Progress] 720/810 batches processed...\n",
            "  [Progress] 730/810 batches processed...\n",
            "  [Progress] 740/810 batches processed...\n",
            "  [Progress] 750/810 batches processed...\n",
            "  [Progress] 760/810 batches processed...\n",
            "  [Progress] 770/810 batches processed...\n",
            "  [Progress] 780/810 batches processed...\n",
            "  [Progress] 790/810 batches processed...\n",
            "  [Progress] 800/810 batches processed...\n",
            "  [Progress] 810/810 batches processed...\n",
            "[INFO]  Total features extracted: (6475, 2048)\n",
            "\n",
            "[STEP 1/2] Extracting testing features...\n",
            "[INFO] Extracting features from 1215 images in 152 steps...\n",
            "  [Progress] 10/152 batches processed...\n",
            "  [Progress] 20/152 batches processed...\n",
            "  [Progress] 30/152 batches processed...\n",
            "  [Progress] 40/152 batches processed...\n",
            "  [Progress] 50/152 batches processed...\n",
            "  [Progress] 60/152 batches processed...\n",
            "  [Progress] 70/152 batches processed...\n",
            "  [Progress] 80/152 batches processed...\n",
            "  [Progress] 90/152 batches processed...\n",
            "  [Progress] 100/152 batches processed...\n",
            "  [Progress] 110/152 batches processed...\n",
            "  [Progress] 120/152 batches processed...\n",
            "  [Progress] 130/152 batches processed...\n",
            "  [Progress] 140/152 batches processed...\n",
            "  [Progress] 150/152 batches processed...\n",
            "[INFO]  Total features extracted: (1215, 2048)\n",
            "[STEP 2/2]  Training features saved: 6475 samples\n",
            "[STEP 2/2]  Testing features saved: 1215 samples\n",
            "\n",
            "[INFO]  Batch_5 completed successfully!\n",
            "\n",
            "Found 6354 images belonging to 2 classes.\n",
            "Found 149 images belonging to 2 classes.\n",
            "\n",
            "============================================================\n",
            "[BATCH] Processing Batch_6\n",
            "============================================================\n",
            "\n",
            "[STEP 1/2] Extracting training features...\n",
            "[INFO] Extracting features from 6354 images in 795 steps...\n",
            "  [Progress] 10/795 batches processed...\n",
            "  [Progress] 20/795 batches processed...\n",
            "  [Progress] 30/795 batches processed...\n",
            "  [Progress] 40/795 batches processed...\n",
            "  [Progress] 50/795 batches processed...\n",
            "  [Progress] 60/795 batches processed...\n",
            "  [Progress] 70/795 batches processed...\n",
            "  [Progress] 80/795 batches processed...\n",
            "  [Progress] 90/795 batches processed...\n",
            "  [Progress] 100/795 batches processed...\n",
            "  [Progress] 110/795 batches processed...\n",
            "  [Progress] 120/795 batches processed...\n",
            "  [Progress] 130/795 batches processed...\n",
            "  [Progress] 140/795 batches processed...\n",
            "  [Progress] 150/795 batches processed...\n",
            "  [Progress] 160/795 batches processed...\n",
            "  [Progress] 170/795 batches processed...\n",
            "  [Progress] 180/795 batches processed...\n",
            "  [Progress] 190/795 batches processed...\n",
            "  [Progress] 200/795 batches processed...\n",
            "  [Progress] 210/795 batches processed...\n",
            "  [Progress] 220/795 batches processed...\n",
            "  [Progress] 230/795 batches processed...\n",
            "  [Progress] 240/795 batches processed...\n",
            "  [Progress] 250/795 batches processed...\n",
            "  [Progress] 260/795 batches processed...\n",
            "  [Progress] 270/795 batches processed...\n",
            "  [Progress] 280/795 batches processed...\n",
            "  [Progress] 290/795 batches processed...\n",
            "  [Progress] 300/795 batches processed...\n",
            "  [Progress] 310/795 batches processed...\n",
            "  [Progress] 320/795 batches processed...\n",
            "  [Progress] 330/795 batches processed...\n",
            "  [Progress] 340/795 batches processed...\n",
            "  [Progress] 350/795 batches processed...\n",
            "  [Progress] 360/795 batches processed...\n",
            "  [Progress] 370/795 batches processed...\n",
            "  [Progress] 380/795 batches processed...\n",
            "  [Progress] 390/795 batches processed...\n",
            "  [Progress] 400/795 batches processed...\n",
            "  [Progress] 410/795 batches processed...\n",
            "  [Progress] 420/795 batches processed...\n",
            "  [Progress] 430/795 batches processed...\n",
            "  [Progress] 440/795 batches processed...\n",
            "  [Progress] 450/795 batches processed...\n",
            "  [Progress] 460/795 batches processed...\n",
            "  [Progress] 470/795 batches processed...\n",
            "  [Progress] 480/795 batches processed...\n",
            "  [Progress] 490/795 batches processed...\n",
            "  [Progress] 500/795 batches processed...\n",
            "  [Progress] 510/795 batches processed...\n",
            "  [Progress] 520/795 batches processed...\n",
            "  [Progress] 530/795 batches processed...\n",
            "  [Progress] 540/795 batches processed...\n",
            "  [Progress] 550/795 batches processed...\n",
            "  [Progress] 560/795 batches processed...\n",
            "  [Progress] 570/795 batches processed...\n",
            "  [Progress] 580/795 batches processed...\n",
            "  [Progress] 590/795 batches processed...\n",
            "  [Progress] 600/795 batches processed...\n",
            "  [Progress] 610/795 batches processed...\n",
            "  [Progress] 620/795 batches processed...\n",
            "  [Progress] 630/795 batches processed...\n",
            "  [Progress] 640/795 batches processed...\n",
            "  [Progress] 650/795 batches processed...\n",
            "  [Progress] 660/795 batches processed...\n",
            "  [Progress] 670/795 batches processed...\n",
            "  [Progress] 680/795 batches processed...\n",
            "  [Progress] 690/795 batches processed...\n",
            "  [Progress] 700/795 batches processed...\n",
            "  [Progress] 710/795 batches processed...\n",
            "  [Progress] 720/795 batches processed...\n",
            "  [Progress] 730/795 batches processed...\n",
            "  [Progress] 740/795 batches processed...\n",
            "  [Progress] 750/795 batches processed...\n",
            "  [Progress] 760/795 batches processed...\n",
            "  [Progress] 770/795 batches processed...\n",
            "  [Progress] 780/795 batches processed...\n",
            "  [Progress] 790/795 batches processed...\n",
            "[INFO]  Total features extracted: (6354, 2048)\n",
            "\n",
            "[STEP 1/2] Extracting testing features...\n",
            "[INFO] Extracting features from 149 images in 19 steps...\n",
            "  [Progress] 10/19 batches processed...\n",
            "[INFO]  Total features extracted: (149, 2048)\n",
            "[STEP 2/2]  Training features saved: 6354 samples\n",
            "[STEP 2/2]  Testing features saved: 149 samples\n",
            "\n",
            "[INFO]  Batch_6 completed successfully!\n",
            "\n",
            "Found 6236 images belonging to 2 classes.\n",
            "Found 59 images belonging to 2 classes.\n",
            "\n",
            "============================================================\n",
            "[BATCH] Processing Batch_7\n",
            "============================================================\n",
            "\n",
            "[STEP 1/2] Extracting training features...\n",
            "[INFO] Extracting features from 6236 images in 780 steps...\n",
            "  [Progress] 10/780 batches processed...\n",
            "  [Progress] 20/780 batches processed...\n",
            "  [Progress] 30/780 batches processed...\n",
            "  [Progress] 40/780 batches processed...\n",
            "  [Progress] 50/780 batches processed...\n",
            "  [Progress] 60/780 batches processed...\n",
            "  [Progress] 70/780 batches processed...\n",
            "  [Progress] 80/780 batches processed...\n",
            "  [Progress] 90/780 batches processed...\n",
            "  [Progress] 100/780 batches processed...\n",
            "  [Progress] 110/780 batches processed...\n",
            "  [Progress] 120/780 batches processed...\n",
            "  [Progress] 130/780 batches processed...\n",
            "  [Progress] 140/780 batches processed...\n",
            "  [Progress] 150/780 batches processed...\n",
            "  [Progress] 160/780 batches processed...\n",
            "  [Progress] 170/780 batches processed...\n",
            "  [Progress] 180/780 batches processed...\n",
            "  [Progress] 190/780 batches processed...\n",
            "  [Progress] 200/780 batches processed...\n",
            "  [Progress] 210/780 batches processed...\n",
            "  [Progress] 220/780 batches processed...\n",
            "  [Progress] 230/780 batches processed...\n",
            "  [Progress] 240/780 batches processed...\n",
            "  [Progress] 250/780 batches processed...\n",
            "  [Progress] 260/780 batches processed...\n",
            "  [Progress] 270/780 batches processed...\n",
            "  [Progress] 280/780 batches processed...\n",
            "  [Progress] 290/780 batches processed...\n",
            "  [Progress] 300/780 batches processed...\n",
            "  [Progress] 310/780 batches processed...\n",
            "  [Progress] 320/780 batches processed...\n",
            "  [Progress] 330/780 batches processed...\n",
            "  [Progress] 340/780 batches processed...\n",
            "  [Progress] 350/780 batches processed...\n",
            "  [Progress] 360/780 batches processed...\n",
            "  [Progress] 370/780 batches processed...\n",
            "  [Progress] 380/780 batches processed...\n",
            "  [Progress] 390/780 batches processed...\n",
            "  [Progress] 400/780 batches processed...\n",
            "  [Progress] 410/780 batches processed...\n",
            "  [Progress] 420/780 batches processed...\n",
            "  [Progress] 430/780 batches processed...\n",
            "  [Progress] 440/780 batches processed...\n",
            "  [Progress] 450/780 batches processed...\n",
            "  [Progress] 460/780 batches processed...\n",
            "  [Progress] 470/780 batches processed...\n",
            "  [Progress] 480/780 batches processed...\n",
            "  [Progress] 490/780 batches processed...\n",
            "  [Progress] 500/780 batches processed...\n",
            "  [Progress] 510/780 batches processed...\n",
            "  [Progress] 520/780 batches processed...\n",
            "  [Progress] 530/780 batches processed...\n",
            "  [Progress] 540/780 batches processed...\n",
            "  [Progress] 550/780 batches processed...\n",
            "  [Progress] 560/780 batches processed...\n",
            "  [Progress] 570/780 batches processed...\n",
            "  [Progress] 580/780 batches processed...\n",
            "  [Progress] 590/780 batches processed...\n",
            "  [Progress] 600/780 batches processed...\n",
            "  [Progress] 610/780 batches processed...\n",
            "  [Progress] 620/780 batches processed...\n",
            "  [Progress] 630/780 batches processed...\n",
            "  [Progress] 640/780 batches processed...\n",
            "  [Progress] 650/780 batches processed...\n",
            "  [Progress] 660/780 batches processed...\n",
            "  [Progress] 670/780 batches processed...\n",
            "  [Progress] 680/780 batches processed...\n",
            "  [Progress] 690/780 batches processed...\n",
            "  [Progress] 700/780 batches processed...\n",
            "  [Progress] 710/780 batches processed...\n",
            "  [Progress] 720/780 batches processed...\n",
            "  [Progress] 730/780 batches processed...\n",
            "  [Progress] 740/780 batches processed...\n",
            "  [Progress] 750/780 batches processed...\n",
            "  [Progress] 760/780 batches processed...\n",
            "  [Progress] 770/780 batches processed...\n",
            "  [Progress] 780/780 batches processed...\n",
            "[INFO]  Total features extracted: (6236, 2048)\n",
            "\n",
            "[STEP 1/2] Extracting testing features...\n",
            "[INFO] Extracting features from 59 images in 8 steps...\n",
            "[INFO]  Total features extracted: (59, 2048)\n",
            "[STEP 2/2]  Training features saved: 6236 samples\n",
            "[STEP 2/2]  Testing features saved: 59 samples\n",
            "\n",
            "[INFO]  Batch_7 completed successfully!\n",
            "\n",
            "Found 6312 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "\n",
            "============================================================\n",
            "[BATCH] Processing Batch_8\n",
            "============================================================\n",
            "\n",
            "[STEP 1/2] Extracting training features...\n",
            "[INFO] Extracting features from 6312 images in 789 steps...\n",
            "  [Progress] 10/789 batches processed...\n",
            "  [Progress] 20/789 batches processed...\n",
            "  [Progress] 30/789 batches processed...\n",
            "  [Progress] 40/789 batches processed...\n",
            "  [Progress] 50/789 batches processed...\n",
            "  [Progress] 60/789 batches processed...\n",
            "  [Progress] 70/789 batches processed...\n",
            "  [Progress] 80/789 batches processed...\n",
            "  [Progress] 90/789 batches processed...\n",
            "  [Progress] 100/789 batches processed...\n",
            "  [Progress] 110/789 batches processed...\n",
            "  [Progress] 120/789 batches processed...\n",
            "  [Progress] 130/789 batches processed...\n",
            "  [Progress] 140/789 batches processed...\n",
            "  [Progress] 150/789 batches processed...\n",
            "  [Progress] 160/789 batches processed...\n",
            "  [Progress] 170/789 batches processed...\n",
            "  [Progress] 180/789 batches processed...\n",
            "  [Progress] 190/789 batches processed...\n",
            "  [Progress] 200/789 batches processed...\n",
            "  [Progress] 210/789 batches processed...\n",
            "  [Progress] 220/789 batches processed...\n",
            "  [Progress] 230/789 batches processed...\n",
            "  [Progress] 240/789 batches processed...\n",
            "  [Progress] 250/789 batches processed...\n",
            "  [Progress] 260/789 batches processed...\n",
            "  [Progress] 270/789 batches processed...\n",
            "  [Progress] 280/789 batches processed...\n",
            "  [Progress] 290/789 batches processed...\n",
            "  [Progress] 300/789 batches processed...\n",
            "  [Progress] 310/789 batches processed...\n",
            "  [Progress] 320/789 batches processed...\n",
            "  [Progress] 330/789 batches processed...\n",
            "  [Progress] 340/789 batches processed...\n",
            "  [Progress] 350/789 batches processed...\n",
            "  [Progress] 360/789 batches processed...\n",
            "  [Progress] 370/789 batches processed...\n",
            "  [Progress] 380/789 batches processed...\n",
            "  [Progress] 390/789 batches processed...\n",
            "  [Progress] 400/789 batches processed...\n",
            "  [Progress] 410/789 batches processed...\n",
            "  [Progress] 420/789 batches processed...\n",
            "  [Progress] 430/789 batches processed...\n",
            "  [Progress] 440/789 batches processed...\n",
            "  [Progress] 450/789 batches processed...\n",
            "  [Progress] 460/789 batches processed...\n",
            "  [Progress] 470/789 batches processed...\n",
            "  [Progress] 480/789 batches processed...\n",
            "  [Progress] 490/789 batches processed...\n",
            "  [Progress] 500/789 batches processed...\n",
            "  [Progress] 510/789 batches processed...\n",
            "  [Progress] 520/789 batches processed...\n",
            "  [Progress] 530/789 batches processed...\n",
            "  [Progress] 540/789 batches processed...\n",
            "  [Progress] 550/789 batches processed...\n",
            "  [Progress] 560/789 batches processed...\n",
            "  [Progress] 570/789 batches processed...\n",
            "  [Progress] 580/789 batches processed...\n",
            "  [Progress] 590/789 batches processed...\n",
            "  [Progress] 600/789 batches processed...\n",
            "  [Progress] 610/789 batches processed...\n",
            "  [Progress] 620/789 batches processed...\n",
            "  [Progress] 630/789 batches processed...\n",
            "  [Progress] 640/789 batches processed...\n",
            "  [Progress] 650/789 batches processed...\n",
            "  [Progress] 660/789 batches processed...\n",
            "  [Progress] 670/789 batches processed...\n",
            "  [Progress] 680/789 batches processed...\n",
            "  [Progress] 690/789 batches processed...\n",
            "  [Progress] 700/789 batches processed...\n",
            "  [Progress] 710/789 batches processed...\n",
            "  [Progress] 720/789 batches processed...\n",
            "  [Progress] 730/789 batches processed...\n",
            "  [Progress] 740/789 batches processed...\n",
            "  [Progress] 750/789 batches processed...\n",
            "  [Progress] 760/789 batches processed...\n",
            "  [Progress] 770/789 batches processed...\n",
            "  [Progress] 780/789 batches processed...\n",
            "[INFO]  Total features extracted: (6312, 2048)\n",
            "\n",
            "[STEP 1/2] Extracting testing features...\n",
            "[INFO] Extracting features from 40 images in 5 steps...\n",
            "[INFO]  Total features extracted: (40, 2048)\n",
            "[STEP 2/2]  Training features saved: 6312 samples\n",
            "[STEP 2/2]  Testing features saved: 40 samples\n",
            "\n",
            "[INFO]  Batch_8 completed successfully!\n",
            "\n",
            "Found 3665 images belonging to 2 classes.\n",
            "Found 702 images belonging to 2 classes.\n",
            "\n",
            "============================================================\n",
            "[BATCH] Processing Batch_9\n",
            "============================================================\n",
            "\n",
            "[STEP 1/2] Extracting training features...\n",
            "[INFO] Extracting features from 3665 images in 459 steps...\n",
            "  [Progress] 10/459 batches processed...\n",
            "  [Progress] 20/459 batches processed...\n",
            "  [Progress] 30/459 batches processed...\n",
            "  [Progress] 40/459 batches processed...\n",
            "  [Progress] 50/459 batches processed...\n",
            "  [Progress] 60/459 batches processed...\n",
            "  [Progress] 70/459 batches processed...\n",
            "  [Progress] 80/459 batches processed...\n",
            "  [Progress] 90/459 batches processed...\n",
            "  [Progress] 100/459 batches processed...\n",
            "  [Progress] 110/459 batches processed...\n",
            "  [Progress] 120/459 batches processed...\n",
            "  [Progress] 130/459 batches processed...\n",
            "  [Progress] 140/459 batches processed...\n",
            "  [Progress] 150/459 batches processed...\n",
            "  [Progress] 160/459 batches processed...\n",
            "  [Progress] 170/459 batches processed...\n",
            "  [Progress] 180/459 batches processed...\n",
            "  [Progress] 190/459 batches processed...\n",
            "  [Progress] 200/459 batches processed...\n",
            "  [Progress] 210/459 batches processed...\n",
            "  [Progress] 220/459 batches processed...\n",
            "  [Progress] 230/459 batches processed...\n",
            "  [Progress] 240/459 batches processed...\n",
            "  [Progress] 250/459 batches processed...\n",
            "  [Progress] 260/459 batches processed...\n",
            "  [Progress] 270/459 batches processed...\n",
            "  [Progress] 280/459 batches processed...\n",
            "  [Progress] 290/459 batches processed...\n",
            "  [Progress] 300/459 batches processed...\n",
            "  [Progress] 310/459 batches processed...\n",
            "  [Progress] 320/459 batches processed...\n",
            "  [Progress] 330/459 batches processed...\n",
            "  [Progress] 340/459 batches processed...\n",
            "  [Progress] 350/459 batches processed...\n",
            "  [Progress] 360/459 batches processed...\n",
            "  [Progress] 370/459 batches processed...\n",
            "  [Progress] 380/459 batches processed...\n",
            "  [Progress] 390/459 batches processed...\n",
            "  [Progress] 400/459 batches processed...\n",
            "  [Progress] 410/459 batches processed...\n",
            "  [Progress] 420/459 batches processed...\n",
            "  [Progress] 430/459 batches processed...\n",
            "  [Progress] 440/459 batches processed...\n",
            "  [Progress] 450/459 batches processed...\n",
            "[INFO]  Total features extracted: (3665, 2048)\n",
            "\n",
            "[STEP 1/2] Extracting testing features...\n",
            "[INFO] Extracting features from 702 images in 88 steps...\n",
            "  [Progress] 10/88 batches processed...\n",
            "  [Progress] 20/88 batches processed...\n",
            "  [Progress] 30/88 batches processed...\n",
            "  [Progress] 40/88 batches processed...\n",
            "  [Progress] 50/88 batches processed...\n",
            "  [Progress] 60/88 batches processed...\n",
            "  [Progress] 70/88 batches processed...\n",
            "  [Progress] 80/88 batches processed...\n",
            "[INFO]  Total features extracted: (702, 2048)\n",
            "[STEP 2/2]  Training features saved: 3665 samples\n",
            "[STEP 2/2]  Testing features saved: 702 samples\n",
            "\n",
            "[INFO]  Batch_9 completed successfully!\n",
            "\n",
            "Found 5943 images belonging to 2 classes.\n",
            "Found 133 images belonging to 2 classes.\n",
            "\n",
            "============================================================\n",
            "[BATCH] Processing Batch_10\n",
            "============================================================\n",
            "\n",
            "[STEP 1/2] Extracting training features...\n",
            "[INFO] Extracting features from 5943 images in 743 steps...\n",
            "  [Progress] 10/743 batches processed...\n",
            "  [Progress] 20/743 batches processed...\n",
            "  [Progress] 30/743 batches processed...\n",
            "  [Progress] 40/743 batches processed...\n",
            "  [Progress] 50/743 batches processed...\n",
            "  [Progress] 60/743 batches processed...\n",
            "  [Progress] 70/743 batches processed...\n",
            "  [Progress] 80/743 batches processed...\n",
            "  [Progress] 90/743 batches processed...\n",
            "  [Progress] 100/743 batches processed...\n",
            "  [Progress] 110/743 batches processed...\n",
            "  [Progress] 120/743 batches processed...\n",
            "  [Progress] 130/743 batches processed...\n",
            "  [Progress] 140/743 batches processed...\n",
            "  [Progress] 150/743 batches processed...\n",
            "  [Progress] 160/743 batches processed...\n",
            "  [Progress] 170/743 batches processed...\n",
            "  [Progress] 180/743 batches processed...\n",
            "  [Progress] 190/743 batches processed...\n",
            "  [Progress] 200/743 batches processed...\n",
            "  [Progress] 210/743 batches processed...\n",
            "  [Progress] 220/743 batches processed...\n",
            "  [Progress] 230/743 batches processed...\n",
            "  [Progress] 240/743 batches processed...\n",
            "  [Progress] 250/743 batches processed...\n",
            "  [Progress] 260/743 batches processed...\n",
            "  [Progress] 270/743 batches processed...\n",
            "  [Progress] 280/743 batches processed...\n",
            "  [Progress] 290/743 batches processed...\n",
            "  [Progress] 300/743 batches processed...\n",
            "  [Progress] 310/743 batches processed...\n",
            "  [Progress] 320/743 batches processed...\n",
            "  [Progress] 330/743 batches processed...\n",
            "  [Progress] 340/743 batches processed...\n",
            "  [Progress] 350/743 batches processed...\n",
            "  [Progress] 360/743 batches processed...\n",
            "  [Progress] 370/743 batches processed...\n",
            "  [Progress] 380/743 batches processed...\n",
            "  [Progress] 390/743 batches processed...\n",
            "  [Progress] 400/743 batches processed...\n",
            "  [Progress] 410/743 batches processed...\n",
            "  [Progress] 420/743 batches processed...\n",
            "  [Progress] 430/743 batches processed...\n",
            "  [Progress] 440/743 batches processed...\n",
            "  [Progress] 450/743 batches processed...\n",
            "  [Progress] 460/743 batches processed...\n",
            "  [Progress] 470/743 batches processed...\n",
            "  [Progress] 480/743 batches processed...\n",
            "  [Progress] 490/743 batches processed...\n",
            "  [Progress] 500/743 batches processed...\n",
            "  [Progress] 510/743 batches processed...\n",
            "  [Progress] 520/743 batches processed...\n",
            "  [Progress] 530/743 batches processed...\n",
            "  [Progress] 540/743 batches processed...\n",
            "  [Progress] 550/743 batches processed...\n",
            "  [Progress] 560/743 batches processed...\n",
            "  [Progress] 570/743 batches processed...\n",
            "  [Progress] 580/743 batches processed...\n",
            "  [Progress] 590/743 batches processed...\n",
            "  [Progress] 600/743 batches processed...\n",
            "  [Progress] 610/743 batches processed...\n",
            "  [Progress] 620/743 batches processed...\n",
            "  [Progress] 630/743 batches processed...\n",
            "  [Progress] 640/743 batches processed...\n",
            "  [Progress] 650/743 batches processed...\n",
            "  [Progress] 660/743 batches processed...\n",
            "  [Progress] 670/743 batches processed...\n",
            "  [Progress] 680/743 batches processed...\n",
            "  [Progress] 690/743 batches processed...\n",
            "  [Progress] 700/743 batches processed...\n",
            "  [Progress] 710/743 batches processed...\n",
            "  [Progress] 720/743 batches processed...\n",
            "  [Progress] 730/743 batches processed...\n",
            "  [Progress] 740/743 batches processed...\n",
            "[INFO]  Total features extracted: (5943, 2048)\n",
            "\n",
            "[STEP 1/2] Extracting testing features...\n",
            "[INFO] Extracting features from 133 images in 17 steps...\n",
            "  [Progress] 10/17 batches processed...\n",
            "[INFO]  Total features extracted: (133, 2048)\n",
            "[STEP 2/2]  Training features saved: 5943 samples\n",
            "[STEP 2/2]  Testing features saved: 133 samples\n",
            "\n",
            "[INFO]  Batch_10 completed successfully!\n",
            "\n",
            "Found 4288 images belonging to 2 classes.\n",
            "Found 546 images belonging to 2 classes.\n",
            "\n",
            "============================================================\n",
            "[BATCH] Processing Batch_11\n",
            "============================================================\n",
            "\n",
            "[STEP 1/2] Extracting training features...\n",
            "[INFO] Extracting features from 4288 images in 536 steps...\n",
            "  [Progress] 10/536 batches processed...\n",
            "  [Progress] 20/536 batches processed...\n",
            "  [Progress] 30/536 batches processed...\n",
            "  [Progress] 40/536 batches processed...\n",
            "  [Progress] 50/536 batches processed...\n",
            "  [Progress] 60/536 batches processed...\n",
            "  [Progress] 70/536 batches processed...\n",
            "  [Progress] 80/536 batches processed...\n",
            "  [Progress] 90/536 batches processed...\n",
            "  [Progress] 100/536 batches processed...\n",
            "  [Progress] 110/536 batches processed...\n",
            "  [Progress] 120/536 batches processed...\n",
            "  [Progress] 130/536 batches processed...\n",
            "  [Progress] 140/536 batches processed...\n",
            "  [Progress] 150/536 batches processed...\n",
            "  [Progress] 160/536 batches processed...\n",
            "  [Progress] 170/536 batches processed...\n",
            "  [Progress] 180/536 batches processed...\n",
            "  [Progress] 190/536 batches processed...\n",
            "  [Progress] 200/536 batches processed...\n",
            "  [Progress] 210/536 batches processed...\n",
            "  [Progress] 220/536 batches processed...\n",
            "  [Progress] 230/536 batches processed...\n",
            "  [Progress] 240/536 batches processed...\n",
            "  [Progress] 250/536 batches processed...\n",
            "  [Progress] 260/536 batches processed...\n",
            "  [Progress] 270/536 batches processed...\n",
            "  [Progress] 280/536 batches processed...\n",
            "  [Progress] 290/536 batches processed...\n",
            "  [Progress] 300/536 batches processed...\n",
            "  [Progress] 310/536 batches processed...\n",
            "  [Progress] 320/536 batches processed...\n",
            "  [Progress] 330/536 batches processed...\n",
            "  [Progress] 340/536 batches processed...\n",
            "  [Progress] 350/536 batches processed...\n",
            "  [Progress] 360/536 batches processed...\n",
            "  [Progress] 370/536 batches processed...\n",
            "  [Progress] 380/536 batches processed...\n",
            "  [Progress] 390/536 batches processed...\n",
            "  [Progress] 400/536 batches processed...\n",
            "  [Progress] 410/536 batches processed...\n",
            "  [Progress] 420/536 batches processed...\n",
            "  [Progress] 430/536 batches processed...\n",
            "  [Progress] 440/536 batches processed...\n",
            "  [Progress] 450/536 batches processed...\n",
            "  [Progress] 460/536 batches processed...\n",
            "  [Progress] 470/536 batches processed...\n",
            "  [Progress] 480/536 batches processed...\n",
            "  [Progress] 490/536 batches processed...\n",
            "  [Progress] 500/536 batches processed...\n",
            "  [Progress] 510/536 batches processed...\n",
            "  [Progress] 520/536 batches processed...\n",
            "  [Progress] 530/536 batches processed...\n",
            "[INFO]  Total features extracted: (4288, 2048)\n",
            "\n",
            "[STEP 1/2] Extracting testing features...\n",
            "[INFO] Extracting features from 546 images in 69 steps...\n",
            "  [Progress] 10/69 batches processed...\n",
            "  [Progress] 20/69 batches processed...\n",
            "  [Progress] 30/69 batches processed...\n",
            "  [Progress] 40/69 batches processed...\n",
            "  [Progress] 50/69 batches processed...\n",
            "  [Progress] 60/69 batches processed...\n",
            "[INFO]  Total features extracted: (546, 2048)\n",
            "[STEP 2/2]  Training features saved: 4288 samples\n",
            "[STEP 2/2]  Testing features saved: 546 samples\n",
            "\n",
            "[INFO]  Batch_11 completed successfully!\n",
            "\n",
            "Found 5856 images belonging to 2 classes.\n",
            "Found 35 images belonging to 2 classes.\n",
            "\n",
            "============================================================\n",
            "[BATCH] Processing Batch_12\n",
            "============================================================\n",
            "\n",
            "[STEP 1/2] Extracting training features...\n",
            "[INFO] Extracting features from 5856 images in 732 steps...\n",
            "  [Progress] 10/732 batches processed...\n",
            "  [Progress] 20/732 batches processed...\n",
            "  [Progress] 30/732 batches processed...\n",
            "  [Progress] 40/732 batches processed...\n",
            "  [Progress] 50/732 batches processed...\n",
            "  [Progress] 60/732 batches processed...\n",
            "  [Progress] 70/732 batches processed...\n",
            "  [Progress] 80/732 batches processed...\n",
            "  [Progress] 90/732 batches processed...\n",
            "  [Progress] 100/732 batches processed...\n",
            "  [Progress] 110/732 batches processed...\n",
            "  [Progress] 120/732 batches processed...\n",
            "  [Progress] 130/732 batches processed...\n",
            "  [Progress] 140/732 batches processed...\n",
            "  [Progress] 150/732 batches processed...\n",
            "  [Progress] 160/732 batches processed...\n",
            "  [Progress] 170/732 batches processed...\n",
            "  [Progress] 180/732 batches processed...\n",
            "  [Progress] 190/732 batches processed...\n",
            "  [Progress] 200/732 batches processed...\n",
            "  [Progress] 210/732 batches processed...\n",
            "  [Progress] 220/732 batches processed...\n",
            "  [Progress] 230/732 batches processed...\n",
            "  [Progress] 240/732 batches processed...\n",
            "  [Progress] 250/732 batches processed...\n",
            "  [Progress] 260/732 batches processed...\n",
            "  [Progress] 270/732 batches processed...\n",
            "  [Progress] 280/732 batches processed...\n",
            "  [Progress] 290/732 batches processed...\n",
            "  [Progress] 300/732 batches processed...\n",
            "  [Progress] 310/732 batches processed...\n",
            "  [Progress] 320/732 batches processed...\n",
            "  [Progress] 330/732 batches processed...\n",
            "  [Progress] 340/732 batches processed...\n",
            "  [Progress] 350/732 batches processed...\n",
            "  [Progress] 360/732 batches processed...\n",
            "  [Progress] 370/732 batches processed...\n",
            "  [Progress] 380/732 batches processed...\n",
            "  [Progress] 390/732 batches processed...\n",
            "  [Progress] 400/732 batches processed...\n",
            "  [Progress] 410/732 batches processed...\n",
            "  [Progress] 420/732 batches processed...\n",
            "  [Progress] 430/732 batches processed...\n",
            "  [Progress] 440/732 batches processed...\n",
            "  [Progress] 450/732 batches processed...\n",
            "  [Progress] 460/732 batches processed...\n",
            "  [Progress] 470/732 batches processed...\n",
            "  [Progress] 480/732 batches processed...\n",
            "  [Progress] 490/732 batches processed...\n",
            "  [Progress] 500/732 batches processed...\n",
            "  [Progress] 510/732 batches processed...\n",
            "  [Progress] 520/732 batches processed...\n",
            "  [Progress] 530/732 batches processed...\n",
            "  [Progress] 540/732 batches processed...\n",
            "  [Progress] 550/732 batches processed...\n",
            "  [Progress] 560/732 batches processed...\n",
            "  [Progress] 570/732 batches processed...\n",
            "  [Progress] 580/732 batches processed...\n",
            "  [Progress] 590/732 batches processed...\n",
            "  [Progress] 600/732 batches processed...\n",
            "  [Progress] 610/732 batches processed...\n",
            "  [Progress] 620/732 batches processed...\n",
            "  [Progress] 630/732 batches processed...\n",
            "  [Progress] 640/732 batches processed...\n",
            "  [Progress] 650/732 batches processed...\n",
            "  [Progress] 660/732 batches processed...\n",
            "  [Progress] 670/732 batches processed...\n",
            "  [Progress] 680/732 batches processed...\n",
            "  [Progress] 690/732 batches processed...\n",
            "  [Progress] 700/732 batches processed...\n",
            "  [Progress] 710/732 batches processed...\n",
            "  [Progress] 720/732 batches processed...\n",
            "  [Progress] 730/732 batches processed...\n",
            "[INFO]  Total features extracted: (5856, 2048)\n",
            "\n",
            "[STEP 1/2] Extracting testing features...\n",
            "[INFO] Extracting features from 35 images in 5 steps...\n",
            "[INFO]  Total features extracted: (35, 2048)\n",
            "[STEP 2/2]  Training features saved: 5856 samples\n",
            "[STEP 2/2]  Testing features saved: 35 samples\n",
            "\n",
            "[INFO]  Batch_12 completed successfully!\n",
            "\n",
            "Found 5925 images belonging to 2 classes.\n",
            "Found 18 images belonging to 2 classes.\n",
            "\n",
            "============================================================\n",
            "[BATCH] Processing Batch_13\n",
            "============================================================\n",
            "\n",
            "[STEP 1/2] Extracting training features...\n",
            "[INFO] Extracting features from 5925 images in 741 steps...\n",
            "  [Progress] 10/741 batches processed...\n",
            "  [Progress] 20/741 batches processed...\n",
            "  [Progress] 30/741 batches processed...\n",
            "  [Progress] 40/741 batches processed...\n",
            "  [Progress] 50/741 batches processed...\n",
            "  [Progress] 60/741 batches processed...\n",
            "  [Progress] 70/741 batches processed...\n",
            "  [Progress] 80/741 batches processed...\n",
            "  [Progress] 90/741 batches processed...\n",
            "  [Progress] 100/741 batches processed...\n",
            "  [Progress] 110/741 batches processed...\n",
            "  [Progress] 120/741 batches processed...\n",
            "  [Progress] 130/741 batches processed...\n",
            "  [Progress] 140/741 batches processed...\n",
            "  [Progress] 150/741 batches processed...\n",
            "  [Progress] 160/741 batches processed...\n",
            "  [Progress] 170/741 batches processed...\n",
            "  [Progress] 180/741 batches processed...\n",
            "  [Progress] 190/741 batches processed...\n",
            "  [Progress] 200/741 batches processed...\n",
            "  [Progress] 210/741 batches processed...\n",
            "  [Progress] 220/741 batches processed...\n",
            "  [Progress] 230/741 batches processed...\n",
            "  [Progress] 240/741 batches processed...\n",
            "  [Progress] 250/741 batches processed...\n",
            "  [Progress] 260/741 batches processed...\n",
            "  [Progress] 270/741 batches processed...\n",
            "  [Progress] 280/741 batches processed...\n",
            "  [Progress] 290/741 batches processed...\n",
            "  [Progress] 300/741 batches processed...\n",
            "  [Progress] 310/741 batches processed...\n",
            "  [Progress] 320/741 batches processed...\n",
            "  [Progress] 330/741 batches processed...\n",
            "  [Progress] 340/741 batches processed...\n",
            "  [Progress] 350/741 batches processed...\n",
            "  [Progress] 360/741 batches processed...\n",
            "  [Progress] 370/741 batches processed...\n",
            "  [Progress] 380/741 batches processed...\n",
            "  [Progress] 390/741 batches processed...\n",
            "  [Progress] 400/741 batches processed...\n",
            "  [Progress] 410/741 batches processed...\n",
            "  [Progress] 420/741 batches processed...\n",
            "  [Progress] 430/741 batches processed...\n",
            "  [Progress] 440/741 batches processed...\n",
            "  [Progress] 450/741 batches processed...\n",
            "  [Progress] 460/741 batches processed...\n",
            "  [Progress] 470/741 batches processed...\n",
            "  [Progress] 480/741 batches processed...\n",
            "  [Progress] 490/741 batches processed...\n",
            "  [Progress] 500/741 batches processed...\n",
            "  [Progress] 510/741 batches processed...\n",
            "  [Progress] 520/741 batches processed...\n",
            "  [Progress] 530/741 batches processed...\n",
            "  [Progress] 540/741 batches processed...\n",
            "  [Progress] 550/741 batches processed...\n",
            "  [Progress] 560/741 batches processed...\n",
            "  [Progress] 570/741 batches processed...\n",
            "  [Progress] 580/741 batches processed...\n",
            "  [Progress] 590/741 batches processed...\n",
            "  [Progress] 600/741 batches processed...\n",
            "  [Progress] 610/741 batches processed...\n",
            "  [Progress] 620/741 batches processed...\n",
            "  [Progress] 630/741 batches processed...\n",
            "  [Progress] 640/741 batches processed...\n",
            "  [Progress] 650/741 batches processed...\n",
            "  [Progress] 660/741 batches processed...\n",
            "  [Progress] 670/741 batches processed...\n",
            "  [Progress] 680/741 batches processed...\n",
            "  [Progress] 690/741 batches processed...\n",
            "  [Progress] 700/741 batches processed...\n",
            "  [Progress] 710/741 batches processed...\n",
            "  [Progress] 720/741 batches processed...\n",
            "  [Progress] 730/741 batches processed...\n",
            "  [Progress] 740/741 batches processed...\n",
            "[INFO]  Total features extracted: (5925, 2048)\n",
            "\n",
            "[STEP 1/2] Extracting testing features...\n",
            "[INFO] Extracting features from 18 images in 3 steps...\n",
            "[INFO]  Total features extracted: (18, 2048)\n",
            "[STEP 2/2]  Training features saved: 5925 samples\n",
            "[STEP 2/2]  Testing features saved: 18 samples\n",
            "\n",
            "[INFO]  Batch_13 completed successfully!\n",
            "\n",
            "Found 5931 images belonging to 2 classes.\n",
            "Found 17 images belonging to 2 classes.\n",
            "\n",
            "============================================================\n",
            "[BATCH] Processing Batch_14\n",
            "============================================================\n",
            "\n",
            "[STEP 1/2] Extracting training features...\n",
            "[INFO] Extracting features from 5931 images in 742 steps...\n",
            "  [Progress] 10/742 batches processed...\n",
            "  [Progress] 20/742 batches processed...\n",
            "  [Progress] 30/742 batches processed...\n",
            "  [Progress] 40/742 batches processed...\n",
            "  [Progress] 50/742 batches processed...\n",
            "  [Progress] 60/742 batches processed...\n",
            "  [Progress] 70/742 batches processed...\n",
            "  [Progress] 80/742 batches processed...\n",
            "  [Progress] 90/742 batches processed...\n",
            "  [Progress] 100/742 batches processed...\n",
            "  [Progress] 110/742 batches processed...\n",
            "  [Progress] 120/742 batches processed...\n",
            "  [Progress] 130/742 batches processed...\n",
            "  [Progress] 140/742 batches processed...\n",
            "  [Progress] 150/742 batches processed...\n",
            "  [Progress] 160/742 batches processed...\n",
            "  [Progress] 170/742 batches processed...\n",
            "  [Progress] 180/742 batches processed...\n",
            "  [Progress] 190/742 batches processed...\n",
            "  [Progress] 200/742 batches processed...\n",
            "  [Progress] 210/742 batches processed...\n",
            "  [Progress] 220/742 batches processed...\n",
            "  [Progress] 230/742 batches processed...\n",
            "  [Progress] 240/742 batches processed...\n",
            "  [Progress] 250/742 batches processed...\n",
            "  [Progress] 260/742 batches processed...\n",
            "  [Progress] 270/742 batches processed...\n",
            "  [Progress] 280/742 batches processed...\n",
            "  [Progress] 290/742 batches processed...\n",
            "  [Progress] 300/742 batches processed...\n",
            "  [Progress] 310/742 batches processed...\n",
            "  [Progress] 320/742 batches processed...\n",
            "  [Progress] 330/742 batches processed...\n",
            "  [Progress] 340/742 batches processed...\n",
            "  [Progress] 350/742 batches processed...\n",
            "  [Progress] 360/742 batches processed...\n",
            "  [Progress] 370/742 batches processed...\n",
            "  [Progress] 380/742 batches processed...\n",
            "  [Progress] 390/742 batches processed...\n",
            "  [Progress] 400/742 batches processed...\n",
            "  [Progress] 410/742 batches processed...\n",
            "  [Progress] 420/742 batches processed...\n",
            "  [Progress] 430/742 batches processed...\n",
            "  [Progress] 440/742 batches processed...\n",
            "  [Progress] 450/742 batches processed...\n",
            "  [Progress] 460/742 batches processed...\n",
            "  [Progress] 470/742 batches processed...\n",
            "  [Progress] 480/742 batches processed...\n",
            "  [Progress] 490/742 batches processed...\n",
            "  [Progress] 500/742 batches processed...\n",
            "  [Progress] 510/742 batches processed...\n",
            "  [Progress] 520/742 batches processed...\n",
            "  [Progress] 530/742 batches processed...\n",
            "  [Progress] 540/742 batches processed...\n",
            "  [Progress] 550/742 batches processed...\n",
            "  [Progress] 560/742 batches processed...\n",
            "  [Progress] 570/742 batches processed...\n",
            "  [Progress] 580/742 batches processed...\n",
            "  [Progress] 590/742 batches processed...\n",
            "  [Progress] 600/742 batches processed...\n",
            "  [Progress] 610/742 batches processed...\n",
            "  [Progress] 620/742 batches processed...\n",
            "  [Progress] 630/742 batches processed...\n",
            "  [Progress] 640/742 batches processed...\n",
            "  [Progress] 650/742 batches processed...\n",
            "  [Progress] 660/742 batches processed...\n",
            "  [Progress] 670/742 batches processed...\n",
            "  [Progress] 680/742 batches processed...\n",
            "  [Progress] 690/742 batches processed...\n",
            "  [Progress] 700/742 batches processed...\n",
            "  [Progress] 710/742 batches processed...\n",
            "  [Progress] 720/742 batches processed...\n",
            "  [Progress] 730/742 batches processed...\n",
            "  [Progress] 740/742 batches processed...\n",
            "[INFO]  Total features extracted: (5931, 2048)\n",
            "\n",
            "[STEP 1/2] Extracting testing features...\n",
            "[INFO] Extracting features from 17 images in 3 steps...\n",
            "[INFO]  Total features extracted: (17, 2048)\n",
            "[STEP 2/2]  Training features saved: 5931 samples\n",
            "[STEP 2/2]  Testing features saved: 17 samples\n",
            "\n",
            "[INFO]  Batch_14 completed successfully!\n",
            "\n",
            "Found 5265 images belonging to 2 classes.\n",
            "Found 183 images belonging to 2 classes.\n",
            "\n",
            "============================================================\n",
            "[BATCH] Processing Batch_15\n",
            "============================================================\n",
            "\n",
            "[STEP 1/2] Extracting training features...\n",
            "[INFO] Extracting features from 5265 images in 659 steps...\n",
            "  [Progress] 10/659 batches processed...\n",
            "  [Progress] 20/659 batches processed...\n",
            "  [Progress] 30/659 batches processed...\n",
            "  [Progress] 40/659 batches processed...\n",
            "  [Progress] 50/659 batches processed...\n",
            "  [Progress] 60/659 batches processed...\n",
            "  [Progress] 70/659 batches processed...\n",
            "  [Progress] 80/659 batches processed...\n",
            "  [Progress] 90/659 batches processed...\n",
            "  [Progress] 100/659 batches processed...\n",
            "  [Progress] 110/659 batches processed...\n",
            "  [Progress] 120/659 batches processed...\n",
            "  [Progress] 130/659 batches processed...\n",
            "  [Progress] 140/659 batches processed...\n",
            "  [Progress] 150/659 batches processed...\n",
            "  [Progress] 160/659 batches processed...\n",
            "  [Progress] 170/659 batches processed...\n",
            "  [Progress] 180/659 batches processed...\n",
            "  [Progress] 190/659 batches processed...\n",
            "  [Progress] 200/659 batches processed...\n",
            "  [Progress] 210/659 batches processed...\n",
            "  [Progress] 220/659 batches processed...\n",
            "  [Progress] 230/659 batches processed...\n",
            "  [Progress] 240/659 batches processed...\n",
            "  [Progress] 250/659 batches processed...\n",
            "  [Progress] 260/659 batches processed...\n",
            "  [Progress] 270/659 batches processed...\n",
            "  [Progress] 280/659 batches processed...\n",
            "  [Progress] 290/659 batches processed...\n",
            "  [Progress] 300/659 batches processed...\n",
            "  [Progress] 310/659 batches processed...\n",
            "  [Progress] 320/659 batches processed...\n",
            "  [Progress] 330/659 batches processed...\n",
            "  [Progress] 340/659 batches processed...\n",
            "  [Progress] 350/659 batches processed...\n",
            "  [Progress] 360/659 batches processed...\n",
            "  [Progress] 370/659 batches processed...\n",
            "  [Progress] 380/659 batches processed...\n",
            "  [Progress] 390/659 batches processed...\n",
            "  [Progress] 400/659 batches processed...\n",
            "  [Progress] 410/659 batches processed...\n",
            "  [Progress] 420/659 batches processed...\n",
            "  [Progress] 430/659 batches processed...\n",
            "  [Progress] 440/659 batches processed...\n",
            "  [Progress] 450/659 batches processed...\n",
            "  [Progress] 460/659 batches processed...\n",
            "  [Progress] 470/659 batches processed...\n",
            "  [Progress] 480/659 batches processed...\n",
            "  [Progress] 490/659 batches processed...\n",
            "  [Progress] 500/659 batches processed...\n",
            "  [Progress] 510/659 batches processed...\n",
            "  [Progress] 520/659 batches processed...\n",
            "  [Progress] 530/659 batches processed...\n",
            "  [Progress] 540/659 batches processed...\n",
            "  [Progress] 550/659 batches processed...\n",
            "  [Progress] 560/659 batches processed...\n",
            "  [Progress] 570/659 batches processed...\n",
            "  [Progress] 580/659 batches processed...\n",
            "  [Progress] 590/659 batches processed...\n",
            "  [Progress] 600/659 batches processed...\n",
            "  [Progress] 610/659 batches processed...\n",
            "  [Progress] 620/659 batches processed...\n",
            "  [Progress] 630/659 batches processed...\n",
            "  [Progress] 640/659 batches processed...\n",
            "  [Progress] 650/659 batches processed...\n",
            "[INFO]  Total features extracted: (5265, 2048)\n",
            "\n",
            "[STEP 1/2] Extracting testing features...\n",
            "[INFO] Extracting features from 183 images in 23 steps...\n",
            "  [Progress] 10/23 batches processed...\n",
            "  [Progress] 20/23 batches processed...\n",
            "[INFO]  Total features extracted: (183, 2048)\n",
            "[STEP 2/2]  Training features saved: 5265 samples\n",
            "[STEP 2/2]  Testing features saved: 183 samples\n",
            "\n",
            "[INFO]  Batch_15 completed successfully!\n",
            "\n",
            "\n",
            "============================================================\n",
            " ALL BATCHES PROCESSED SUCCESSFULLY!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import Xception\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
        "import gc\n",
        "\n",
        "# =========================================\n",
        "#  GPU MEMORY MANAGEMENT\n",
        "# =========================================\n",
        "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "# for gpu in gpus:\n",
        "#     tf.config.experimental.set_memory_growth(gpu, True)\n",
        "\n",
        "# Use mixed precision (reduces memory by ~40%)\n",
        "from tensorflow.keras import mixed_precision\n",
        "mixed_precision.set_global_policy('mixed_float16')\n",
        "\n",
        "# =========================================\n",
        "#  GLOBAL MODEL CACHE - REUSE ACROSS BATCHES\n",
        "# =========================================\n",
        "_cached_model = None\n",
        "\n",
        "def get_feature_extraction_model():\n",
        "    \"\"\"Get cached or create new model for feature extraction\"\"\"\n",
        "    global _cached_model\n",
        "    if _cached_model is None:\n",
        "        base_model = Xception(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
        "        output_pooled = GlobalAveragePooling2D()(base_model.output)\n",
        "        output_4 = Dense(2048, activation='relu')(output_pooled)\n",
        "        _cached_model = Model(inputs=base_model.input, outputs=output_4)\n",
        "        \n",
        "        # Freeze all layers\n",
        "        for layer in base_model.layers:\n",
        "            layer.trainable = False\n",
        "        print(\"[INFO]  Feature extraction model loaded (cached)\")\n",
        "    return _cached_model\n",
        "\n",
        "# =========================================\n",
        "#  OPTIMIZED FEATURE EXTRACTION - FULL DATA SUPPORT\n",
        "# =========================================\n",
        "def extract_features_in_chunks(generator, model, chunk_size=32):\n",
        "    \"\"\"\n",
        "    Extract features in chunks to manage memory efficiently.\n",
        "    Handles full dataset regardless of size.\n",
        "    \"\"\"\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "    all_filenames = []\n",
        "    \n",
        "    # Calculate total steps needed\n",
        "    total_samples = len(generator.filenames)\n",
        "    steps = int(np.ceil(total_samples / generator.batch_size))\n",
        "    \n",
        "    print(f\"[INFO] Extracting features from {total_samples} images in {steps} steps...\")\n",
        "    \n",
        "    for step in range(steps):\n",
        "        try:\n",
        "            batch_x, batch_y = next(generator)\n",
        "            chunk_features = model.predict(batch_x, verbose=0)\n",
        "            all_features.append(chunk_features)\n",
        "            all_labels.extend(batch_y if isinstance(batch_y, (list, np.ndarray)) and len(batch_y.shape) == 1 \n",
        "                            else np.argmax(batch_y, axis=1))\n",
        "            all_filenames.extend(generator.filenames[step*generator.batch_size:(step+1)*generator.batch_size])\n",
        "            \n",
        "            if (step + 1) % 10 == 0:\n",
        "                print(f\"  [Progress] {step + 1}/{steps} batches processed...\")\n",
        "                gc.collect()\n",
        "        except StopIteration:\n",
        "            break\n",
        "    \n",
        "    # Concatenate all features\n",
        "    features_array = np.vstack(all_features)\n",
        "    print(f\"[INFO]  Total features extracted: {features_array.shape}\")\n",
        "    \n",
        "    return features_array, np.array(all_labels), all_filenames[:len(all_labels)]\n",
        "\n",
        "# =========================================\n",
        "#  MAIN OPTIMIZED FUNCTION - FEATURE EXTRACTION ONLY\n",
        "# =========================================\n",
        "def XceptionNet2048_Features_Optimized(train_generator, test_generator, Batch):\n",
        "    \"\"\"\n",
        "    Optimized feature extraction (100% data support).\n",
        "    - Supports 100% data processing (not just 40%)\n",
        "    - Memory-efficient chunked processing\n",
        "    - Cached model across batches\n",
        "    - Saves features to CSV\n",
        "    \"\"\"\n",
        "    \n",
        "    # Setup paths\n",
        "    current_dir = os.path.dirname(os.path.abspath('__file__'))\n",
        "    parent_dir = os.path.dirname(current_dir)\n",
        "    root_dir = os.path.dirname(parent_dir)\n",
        "    save_drive_dir = os.path.join(root_dir, 'pathologyStudentsAug25', 'Results', 'XceptionNet2048+SVM')\n",
        "    batch_output_dir = os.path.join(save_drive_dir, Batch)\n",
        "    os.makedirs(batch_output_dir, exist_ok=True)\n",
        "    \n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"[BATCH] Processing {Batch}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Get cached model\n",
        "    model = get_feature_extraction_model()\n",
        "    \n",
        "    #  FEATURE EXTRACTION - FULL DATA (100%)\n",
        "    print(f\"\\n[STEP 1/2] Extracting training features...\")\n",
        "    features_train, labels_train, filenames_train = extract_features_in_chunks(\n",
        "        train_generator, model, chunk_size=32\n",
        "    )\n",
        "    \n",
        "    print(f\"\\n[STEP 1/2] Extracting testing features...\")\n",
        "    features_test, labels_test, filenames_test = extract_features_in_chunks(\n",
        "        test_generator, model, chunk_size=32\n",
        "    )\n",
        "    \n",
        "    #  SAVE RAW FEATURES\n",
        "    columns_2048 = [f'feature_{c}' for c in range(features_train.shape[1])]\n",
        "    \n",
        "    df_train = pd.DataFrame(features_train, columns=columns_2048)\n",
        "    df_train['label'] = labels_train\n",
        "    df_train['Image_Name'] = filenames_train\n",
        "    df_train.to_csv(os.path.join(batch_output_dir, 'XceptionNet2048_Training.csv'), index=False)\n",
        "    print(f\"[STEP 2/2]  Training features saved: {df_train.shape[0]} samples\")\n",
        "    \n",
        "    df_test = pd.DataFrame(features_test, columns=columns_2048)\n",
        "    df_test['label'] = labels_test\n",
        "    df_test['Image_Name'] = filenames_test\n",
        "    df_test.to_csv(os.path.join(batch_output_dir, 'XceptionNet2048_Testing.csv'), index=False)\n",
        "    print(f\"[STEP 2/2]  Testing features saved: {df_test.shape[0]} samples\")\n",
        "    \n",
        "    # Memory cleanup\n",
        "    del features_train, features_test, df_train, df_test\n",
        "    gc.collect()\n",
        "    tf.keras.backend.clear_session()\n",
        "    \n",
        "    print(f\"\\n[INFO]  {Batch} completed successfully!\\n\")\n",
        "\n",
        "# =========================================\n",
        "#  LOOP THROUGH BATCHES - PROCESS ALL DATA\n",
        "# =========================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"STARTING OPTIMIZED BATCH PROCESSING - FULL DATA (100%)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for x in range(1, 16):\n",
        "    batch_size = 8  #  Optimized batch size\n",
        "    Batch_Name = f'Batch_{x}'\n",
        "    \n",
        "    current_dir = os.path.dirname(os.path.abspath('__file__'))\n",
        "    parent_dir = os.path.dirname(current_dir)\n",
        "    root_dir = os.path.dirname(parent_dir)\n",
        "    \n",
        "    save_dir = os.path.join(root_dir, 'pathologyStudentsAug25', 'Results', 'XceptionNet2048+SVM')\n",
        "    os.makedirs(os.path.join(save_dir, Batch_Name), exist_ok=True)\n",
        "    \n",
        "    Training_Path = os.path.join(root_dir, 'pathologyStudentsAug25', 'original', Batch_Name, 'Training')\n",
        "    Testing_Path = os.path.join(root_dir, 'pathologyStudentsAug25', 'original', Batch_Name, 'Testing')\n",
        "    \n",
        "    if not os.path.exists(Training_Path):\n",
        "        print(f\"[WARNING] Skipping {Batch_Name} - path not found: {Training_Path}\")\n",
        "        continue\n",
        "    \n",
        "    # Data generators with NO shuffle (ensures proper ordering)\n",
        "    train_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "    test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "    \n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        Training_Path,\n",
        "        target_size=(256, 256),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        classes=['Non_Necrosis', 'Necrosis'],\n",
        "        seed=42\n",
        "    )\n",
        "    \n",
        "    test_generator = test_datagen.flow_from_directory(\n",
        "        Testing_Path,\n",
        "        target_size=(256, 256),\n",
        "        batch_size=batch_size,\n",
        "        shuffle=False,\n",
        "        classes=['Non_Necrosis', 'Necrosis'],\n",
        "        seed=42\n",
        "    )\n",
        "    \n",
        "    # Process batch with optimized function\n",
        "    XceptionNet2048_Features_Optimized(\n",
        "        train_generator, test_generator, Batch_Name\n",
        "    )\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\" ALL BATCHES PROCESSED SUCCESSFULLY!\")\n",
        "print(\"=\"*60)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "exIH8aJ7vzlN"
      },
      "outputs": [],
      "source": [
        "def XceptionNet2048_SVM(train_generator, test_generator, Batch):\n",
        "  # Get the current notebook's directory and navigate to the correct location\n",
        "  current_dir = os.path.dirname(os.path.abspath('__file__'))\n",
        "  parent_dir = os.path.dirname(current_dir)\n",
        "  root_dir = os.path.dirname(parent_dir)\n",
        "  \n",
        "  save_drive_dir = os.path.join(root_dir, 'pathologyStudentsAug25', 'Results', 'XceptionNet2048+SVM')\n",
        "  batch_size = 32\n",
        "  \n",
        "  model_Xception = Model(base_model_Xception.input, output)\n",
        "  for layer in base_model_Xception.layers[:-4]:\n",
        "    layer.trainable = True\n",
        "\n",
        "  model_Xception_features_2048 = Model(base_model_Xception.input, output_4)\n",
        "\n",
        "  columns_2048 = []\n",
        "  for c in range(2048):\n",
        "    columns_2048.append('feature_'+str(c))\n",
        "\n",
        "  features_2048_train = model_Xception_features_2048.predict(train_generator)\n",
        "  df_2048_train = pd.DataFrame(features_2048_train, columns=columns_2048)\n",
        "  df_2048_train['label'] = train_generator.labels\n",
        "  df_2048_train['Image_Name'] = train_generator.filenames\n",
        "  df_2048_train.to_csv(os.path.join(save_drive_dir, Batch, 'XceptionNet2048_Training.csv'))\n",
        "\n",
        "  features_2048_test = model_Xception_features_2048.predict(test_generator)\n",
        "  df_2048_test = pd.DataFrame(features_2048_test, columns=columns_2048)\n",
        "  df_2048_test['label'] = test_generator.labels\n",
        "  df_2048_test['Image_Name'] = test_generator.filenames\n",
        "  df_2048_test.to_csv(os.path.join(save_drive_dir, Batch, 'XceptionNet2048_Testing.csv'))\n",
        "\n",
        "  # Train = pd.read_csv(os.path.join(save_drive_dir, Batch, 'XceptionNet2048_Training.csv'))\n",
        "  # Test = pd.read_csv(os.path.join(save_drive_dir, Batch, 'XceptionNet2048_Testing.csv'))\n",
        "\n",
        "  # Train = Train.drop(['Unnamed: 0','Image_Name'], axis=1)\n",
        "  # Test = Test.drop(['Unnamed: 0','Image_Name'], axis=1)\n",
        "\n",
        "  # X_train = Train.iloc[:,:-1].values\n",
        "  # Y_train = Train.iloc[:,-1].values\n",
        "\n",
        "  # X_test = Test.iloc[:,:-1].values\n",
        "  # Y_test = Test.iloc[:,-1].values\n",
        "\n",
        "  # model = SVC(probability=True)\n",
        "  # model.fit(X_train, Y_train)\n",
        "  # y_pred = model.predict(X_test)\n",
        "  # probability = model.predict_proba(X_test)\n",
        "  # cm = confusion_matrix(Y_test, y_pred)\n",
        "  # TP = cm[0][0]\n",
        "  # TN = cm[1][1]\n",
        "  # FP = cm[0][1]\n",
        "  # FN = cm[1][0]\n",
        "  # precision = precision_score(Y_test, y_pred)\n",
        "  # recall = recall_score(Y_test, y_pred)\n",
        "  # f1score = f1_score(Y_test, y_pred)\n",
        "  # accuracy = accuracy_score(Y_test, y_pred)\n",
        "  # sensitivity = TP/(TP+FN)\n",
        "  # specificity = TN/(FP+TN)\n",
        "  # NPV = TN/(TN+FN)\n",
        "  # PPV = TP/(TP+FP)\n",
        "  # mcc = matthews_corrcoef(Y_test, y_pred)\n",
        "  # kappa_score = cohen_kappa_score(Y_test, y_pred)\n",
        "  # auc_score = roc_auc_score(Y_test, probability[:,1])\n",
        "  # columns_metrics = ['model_Name','Necrosis','Non_Necrosis','TP','TN','FP','FN','Accuracy','Recall','F1_score','Precision','AUC_ROC','Sensitiviity','Specificity','MCC','Kappa_Score']\n",
        "\n",
        "  # dff_metrics = pd.DataFrame(columns=columns_metrics)\n",
        "\n",
        "  # batch_dir = os.path.join(root_dir, 'pathologyStudentsAug25', Batch)\n",
        "  # Necrosis_samples = len(os.listdir(os.path.join(batch_dir, 'Testing', 'Necrosis')))\n",
        "  # Non_Necrosis_samples = len(os.listdir(os.path.join(batch_dir, 'Testing', 'Non_Necrosis')))\n",
        "\n",
        "  # values = ['XceptionNet2048+SVM',Necrosis_samples,Non_Necrosis_samples,TP,TN,FP,FN,accuracy,recall,f1score,precision,auc_score,sensitivity,specificity,mcc,kappa_score]\n",
        "  # dff_metrics.loc[0] = values\n",
        "  # dff_metrics.to_csv(os.path.join(save_drive_dir, Batch, 'XceptionNet2048+SVM_results.csv'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw4Cewupv1cu",
        "outputId": "137572f5-d086-48a5-82cd-cccb0f67bc71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch Name Batch_1\n",
            "Training Path d:\\pathologyStudentsAug25\\pathologyStudentsAug25\\Batch_1\\Training\n",
            "Testing Path d:\\pathologyStudentsAug25\\pathologyStudentsAug25\\Batch_1\\Testing\n",
            "Found 3169 images belonging to 2 classes.\n",
            "Found 33 images belonging to 2 classes.\n",
            "\u001b[1m  5/100\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m2:16:01\u001b[0m 86s/step"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch Name Batch_1\n",
            "Training Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_1/Training\n",
            "Testing Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_1/Testing\n",
            "Found 3169 images belonging to 2 classes.\n",
            "Found 33 images belonging to 2 classes.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-11-11 11:53:23.299186: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91300\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m100/100\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 206ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 149ms/step\n",
            "Batch Name Batch_2\n",
            "Training Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_2/Training\n",
            "Testing Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_2/Testing\n",
            "Found 2868 images belonging to 2 classes.\n",
            "Found 183 images belonging to 2 classes.\n",
            "\u001b[1m90/90\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 205ms/step\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 165ms/step\n",
            "Batch Name Batch_3\n",
            "Training Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_3/Training\n",
            "Testing Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_3/Testing\n",
            "Found 3204 images belonging to 2 classes.\n",
            "Found 15 images belonging to 2 classes.\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 171ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 340ms/step\n",
            "Batch Name Batch_4\n",
            "Training Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_4/Training\n",
            "Testing Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_4/Testing\n",
            "Found 3192 images belonging to 2 classes.\n",
            "Found 564 images belonging to 2 classes.\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 157ms/step\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 176ms/step\n",
            "Batch Name Batch_5\n",
            "Training Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_5/Training\n",
            "Testing Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_5/Testing\n",
            "Found 3235 images belonging to 2 classes.\n",
            "Found 1215 images belonging to 2 classes.\n",
            "\u001b[1m102/102\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 200ms/step\n",
            "\u001b[1m38/38\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 170ms/step\n",
            "Batch Name Batch_6\n",
            "Training Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_6/Training\n",
            "Testing Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_6/Testing\n",
            "Found 3175 images belonging to 2 classes.\n",
            "Found 149 images belonging to 2 classes.\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 187ms/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 156ms/step\n",
            "Batch Name Batch_7\n",
            "Training Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_7/Training\n",
            "Testing Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_7/Testing\n",
            "Found 3116 images belonging to 2 classes.\n",
            "Found 59 images belonging to 2 classes.\n",
            "\u001b[1m98/98\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 177ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 278ms/step\n",
            "Batch Name Batch_8\n",
            "Training Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_8/Training\n",
            "Testing Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_8/Testing\n",
            "Found 3154 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "\u001b[1m99/99\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 193ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
            "Batch Name Batch_9\n",
            "Training Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_9/Training\n",
            "Testing Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_9/Testing\n",
            "Found 1831 images belonging to 2 classes.\n",
            "Found 702 images belonging to 2 classes.\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 176ms/step\n",
            "\u001b[1m22/22\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 172ms/step\n",
            "Batch Name Batch_10\n",
            "Training Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_10/Training\n",
            "Testing Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_10/Testing\n",
            "Found 2969 images belonging to 2 classes.\n",
            "Found 133 images belonging to 2 classes.\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 167ms/step\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 141ms/step\n",
            "Batch Name Batch_11\n",
            "Training Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_11/Training\n",
            "Testing Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_11/Testing\n",
            "Found 2142 images belonging to 2 classes.\n",
            "Found 546 images belonging to 2 classes.\n",
            "\u001b[1m67/67\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 139ms/step\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 179ms/step\n",
            "Batch Name Batch_12\n",
            "Training Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_12/Training\n",
            "Testing Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_12/Testing\n",
            "Found 2926 images belonging to 2 classes.\n",
            "Found 35 images belonging to 2 classes.\n",
            "\u001b[1m92/92\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 167ms/step\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step\n",
            "Batch Name Batch_13\n",
            "Training Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_13/Training\n",
            "Testing Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_13/Testing\n",
            "Found 2960 images belonging to 2 classes.\n",
            "Found 18 images belonging to 2 classes.\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 191ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 208ms/step\n",
            "Batch Name Batch_14\n",
            "Training Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_14/Training\n",
            "Testing Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_14/Testing\n",
            "Found 2963 images belonging to 2 classes.\n",
            "Found 17 images belonging to 2 classes.\n",
            "\u001b[1m93/93\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 186ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step\n",
            "Batch Name Batch_15\n",
            "Training Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_15/Training\n",
            "Testing Path /home/llmPathoUser/pathologyStudentsAug25/pathologyStudentsAug25/Batch_15/Testing\n",
            "Found 2630 images belonging to 2 classes.\n",
            "Found 183 images belonging to 2 classes.\n",
            "\u001b[1m83/83\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 195ms/step\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 164ms/step\n"
          ]
        }
      ],
      "source": [
        "for x in range(1,16):\n",
        "  batch_size = 32\n",
        "  Batch_Name = f'Batch_{x}'\n",
        "  print('Batch Name', Batch_Name)\n",
        "  \n",
        "  # Get the current notebook's directory and navigate to the correct location\n",
        "  current_dir = os.path.dirname(os.path.abspath('__file__'))\n",
        "  parent_dir = os.path.dirname(current_dir)\n",
        "  root_dir = os.path.dirname(parent_dir)\n",
        "  \n",
        "  # Set up paths\n",
        "  save_dir = os.path.join(root_dir, 'pathologyStudentsAug25', 'Results', 'XceptionNet2048+SVM')\n",
        "  os.makedirs(os.path.join(save_dir, Batch_Name), exist_ok=True)\n",
        "\n",
        "  Training_Path = os.path.join(root_dir, 'pathologyStudentsAug25', Batch_Name, 'Training')\n",
        "  Testing_Path = os.path.join(root_dir, 'pathologyStudentsAug25', Batch_Name, 'Testing')\n",
        "\n",
        "  print('Training Path', Training_Path)\n",
        "  print('Testing Path', Testing_Path)\n",
        "  \n",
        "  train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "  test_datagen = ImageDataGenerator(rescale=1 / 255.0)\n",
        "\n",
        "  train_generator = train_datagen.flow_from_directory(\n",
        "      directory=Training_Path,\n",
        "      target_size=(256, 256),\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False,\n",
        "      classes=['Non_Necrosis','Necrosis'],\n",
        "      subset='training',\n",
        "      seed=42)\n",
        "\n",
        "  test_generator = test_datagen.flow_from_directory(\n",
        "      directory=Testing_Path,\n",
        "      target_size=(256, 256),\n",
        "      batch_size=batch_size,\n",
        "      shuffle=False,\n",
        "      classes=['Non_Necrosis','Necrosis'],\n",
        "      seed=42\n",
        "      )\n",
        "  XceptionNet2048_SVM(train_generator, test_generator, Batch_Name)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "env (3.12.3)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
